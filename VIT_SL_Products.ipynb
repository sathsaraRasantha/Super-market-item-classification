{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "961ccce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import glob\n",
    "import pytorch_lightning as pl\n",
    "from huggingface_hub import HfApi, Repository\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchmetrics import Accuracy\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f7b6a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"/home/orelit/Projects -Sathsara/Planigo/data/Sri Lankan_Final\")\n",
    "\n",
    "ds=ImageFolder(data_dir)\n",
    "indices = torch.randperm(len(ds)).tolist()\n",
    "n_val = math.floor(len(indices) * .15)\n",
    "train_ds = torch.utils.data.Subset(ds, indices[:-n_val])\n",
    "val_ds = torch.utils.data.Subset(ds, indices[-n_val:])\n",
    "\n",
    "\n",
    "label2id = {}\n",
    "id2label = {}\n",
    "for i, class_name in enumerate(ds.classes):\n",
    "  label2id[class_name] = str(i)\n",
    "  id2label[str(i)] = class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6187a172",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {}\n",
    "id2label = {}\n",
    "for i, class_name in enumerate(ds.classes):\n",
    "  label2id[class_name] = str(i)\n",
    "  id2label[str(i)] = class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab0a042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/home/orelit/Projects -Sathsara/Planigo/Models/VIT_SL_new/label2id.json', 'w') as fp:\n",
    "    json.dump(label2id, fp)\n",
    "    \n",
    "with open('/home/orelit/Projects -Sathsara/Planigo/Models/VIT_SL_new/id2label.json', 'w') as fp:\n",
    "    json.dump(id2label, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03243b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "class ImageClassificationCollator:\n",
    "   def __init__(self, feature_extractor): \n",
    "      self.feature_extractor = feature_extractor\n",
    "   def __call__(self, batch):  \n",
    "      encodings = self.feature_extractor([x[0] for x in batch],\n",
    "      return_tensors='pt')   \n",
    "      encodings['labels'] = torch.tensor([x[1] for x in batch],    \n",
    "      dtype=torch.long)\n",
    "      return encodings\n",
    "\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "collator = ImageClassificationCollator(feature_extractor)\n",
    "train_loader = DataLoader(train_ds, batch_size=32, \n",
    "   collate_fn=collator, num_workers=2, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=32, collate_fn=collator, \n",
    "   num_workers=2)\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "        'google/vit-base-patch16-224-in21k',\n",
    "         num_labels=len(label2id),\n",
    "         label2id=label2id,\n",
    "         id2label=id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2af9999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(pl.LightningModule):\n",
    "   def __init__(self, model, lr: float = 2e-5, **kwargs): \n",
    "       super().__init__()\n",
    "       self.save_hyperparameters('lr', *list(kwargs))\n",
    "       self.model = model\n",
    "       self.forward = self.model.forward \n",
    "       self.val_acc = Accuracy()\n",
    "   def training_step(self, batch, batch_idx):\n",
    "       outputs = self(**batch)\n",
    "       self.log(f\"train_loss\", outputs.loss)\n",
    "       return outputs.loss\n",
    "   def validation_step(self, batch, batch_idx):\n",
    "       outputs = self(**batch)\n",
    "       self.log(f\"val_loss\", outputs.loss)\n",
    "       acc = self.val_acc(outputs.logits.argmax(1), batch['labels'])\n",
    "       self.log(f\"val_acc\", acc, prog_bar=True)\n",
    "       return outputs.loss\n",
    "   def configure_optimizers(self):\n",
    "       return torch.optim.Adam(self.parameters(), \n",
    "                        lr=self.hparams.lr,weight_decay = 0.00025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "559b6035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "/home/orelit/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type                      | Params\n",
      "------------------------------------------------------\n",
      "0 | model   | ViTForImageClassification | 85.8 M\n",
      "1 | val_acc | Accuracy                  | 0     \n",
      "------------------------------------------------------\n",
      "85.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "85.8 M    Total params\n",
      "171.605   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orelit/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/orelit/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/orelit/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1892: PossibleUserWarning: The number of training batches (47) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9341327f9b834e69a4f78950e23438a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(42)\n",
    "classifier = Classifier(model, lr=2e-5)\n",
    "trainer = pl.Trainer(gpus=1, precision=16, max_epochs=10)\n",
    "trainer.fit(classifier, train_loader, val_loader)\n",
    "\n",
    "model.save_pretrained(\"/home/orelit/Projects -Sathsara/Planigo/Models/VIT_SL_new/model_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f754f83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "234d4d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/home/orelit/Projects -Sathsara/Planigo/Models/VIT_SL_new/model_1'\n",
    "SL_prod_model = ViTForImageClassification.from_pretrained(\n",
    "         model_path,\n",
    "         num_labels=len(label2id),\n",
    "         label2id=label2id,\n",
    "         id2label=id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08bfa2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26c6038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(img_path):\n",
    "   im=Image.open(img_path)\n",
    "   encoding = feature_extractor(images=im, return_tensors=\"pt\")\n",
    "   encoding.keys()\n",
    "   pixel_values = encoding['pixel_values']\n",
    "   outputs = SL_prod_model(pixel_values)\n",
    "   result = outputs.logits.softmax(1).argmax(1)\n",
    "   tensor_result = outputs.logits.softmax(1)\n",
    "   prob = torch.max(tensor_result)\n",
    "   new_result = result.tolist() \n",
    "   for i in new_result:\n",
    "     return(id2label[str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c223577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "test_data_path = '/home/orelit/Projects -Sathsara/Planigo/data/sri_lankan_test_images/All_barcodes'\n",
    "\n",
    "image_paths = []\n",
    "for image in os.listdir(test_data_path):\n",
    "    img = test_data_path +'/'+image\n",
    "    image_paths.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6ff5cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction :  4792229216206\n",
      "Real Label :  4792229216206\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  4796918130712\n",
      "Real Label :  4796918130712\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  8901030732911\n",
      "Real Label :  8901030732911\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  4792143282417\n",
      "Real Label :  4792143282417\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  4792037767266\n",
      "Real Label :  4792037767266\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  4792143280413\n",
      "Real Label :  4792143280413\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  4792229216206\n",
      "Real Label :  4792229216206\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  4792149097107\n",
      "Real Label :  4792149097107\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  4792068181130\n",
      "Real Label :  4792068181130\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  8901499007704\n",
      "Real Label :  8901499007704\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  4796002401001\n",
      "Real Label :  4796002401001\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  4796918130194\n",
      "Real Label :  4796918130194\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  4792090000546\n",
      "Real Label :  4792090000546\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  4792024015684\n",
      "Real Label :  4792024015684\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  4792143280314\n",
      "Real Label :  4792143280314\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  93286\n",
      "Real Label :  93286\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  6005044004070\n",
      "Real Label :  6005044004070\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  8888101611262\n",
      "Real Label :  8888101612269\n",
      "Misclassified\n",
      ".....................................\n",
      "Prediction :  8888002086008\n",
      "Real Label :  8888002086008\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  4792090000546\n",
      "Real Label :  4792090000546\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  6005044001451\n",
      "Real Label :  6005044001451\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  8888101611262\n",
      "Real Label :  8888101611262\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  4792024015684\n",
      "Real Label :  4792024015684\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  4792024015769\n",
      "Real Label :  4792024015769\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  4791111152028\n",
      "Real Label :  4791111152028\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  4791111152028\n",
      "Real Label :  4791111152028\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  4792068181130\n",
      "Real Label :  4792068181130\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  4792024015769\n",
      "Real Label :  4792024015769\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  4792225700976\n",
      "Real Label :  4792225700976\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  4792081014040\n",
      "Real Label :  4792081014040\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  4796006420183\n",
      "Real Label :  4796006420183\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  4792024015684\n",
      "Real Label :  4792024015684\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  4792143280314\n",
      "Real Label :  4792143280314\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  4796002403005\n",
      "Real Label :  4796002403005\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  8901030732911\n",
      "Real Label :  8901030732911\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  4792081001859\n",
      "Real Label :  4792081001859\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  4791061000004\n",
      "Real Label :  4791061000004\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  4792069001383\n",
      "Real Label :  4792069001383\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  93286\n",
      "Real Label :  93286\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  4791111152226\n",
      "Real Label :  4791111152226\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  4792143282417\n",
      "Real Label :  4792143282417\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  8901030732911\n",
      "Real Label :  8901030732911\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Number of images :  42\n",
      "Number of correctly classified images :  41\n",
      "Accuray :  0.9761904761904762\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "count = 0\n",
    "correct = 0\n",
    "for image in os.listdir(test_data_path):\n",
    "    if len(image)>=18:\n",
    "        img = test_data_path +'/'+image\n",
    "        pred= prediction(img)\n",
    "        print('Prediction : ',pred)\n",
    "        test_label = image[image.rfind('/')+1:]\n",
    "        real_class = test_label[0:13]\n",
    "        print('Real Label : ',real_class)\n",
    "        if real_class == pred:\n",
    "            correct = correct +1\n",
    "            print('Correctly Classified')\n",
    "        else:\n",
    "            print('Misclassified')\n",
    "        count = count + 1\n",
    "        print('.....................................')\n",
    "    \n",
    "    else:\n",
    "        img = test_data_path +'/'+image\n",
    "        pred= prediction(img)\n",
    "        print('Prediction : ',pred)\n",
    "        test_label = image[image.rfind('/')+1:]\n",
    "        real_class = test_label[0:5]\n",
    "        print('Real Label : ',real_class)\n",
    "        if real_class == pred:\n",
    "            correct = correct +1\n",
    "            print('Correctly Classified')\n",
    "        else:\n",
    "            print('Misclassified')\n",
    "        count = count + 1\n",
    "        print('.....................................')\n",
    "    \n",
    "acc = correct/count\n",
    "print(\"Number of images : \",count)\n",
    "print(\"Number of correctly classified images : \",correct)\n",
    "print(\"Accuray : \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89b0b57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "def imlist(path):\n",
    "    return [os.path.join(path, f) for f in os.listdir(path)]\n",
    "\n",
    "def copy_images(imagePaths, folder):\n",
    "\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "    for path in imagePaths:\n",
    "\n",
    "        imageName = path.split(os.path.sep)[-1]\n",
    "        label = path.split(os.path.sep)[-2]\n",
    "        labelFolder = os.path.join(folder, label)\n",
    "\n",
    "        if not os.path.exists(labelFolder):\n",
    "            os.makedirs(labelFolder)\n",
    "\n",
    "            destination = os.path.join(labelFolder, imageName)\n",
    "            shutil.copy(path, destination)\n",
    "\n",
    "\n",
    "path = \"/home/orelit/Projects -Sathsara/Planigo/data/VIT_train_wine_low_variance_test_augmented\"\n",
    "\n",
    "items =os.listdir(path)\n",
    "\n",
    "for item in items:\n",
    "    imagePaths = list(imlist('/home/orelit/Projects -Sathsara/Planigo/data/VIT_train_wine_low_variance_test_augmented/{}'.format(item)))\n",
    "    np.random.shuffle(imagePaths)\n",
    "    valPathsLen = int(len(imagePaths) * 0.2)\n",
    "    trainPathsLen = len(imagePaths) - valPathsLen\n",
    "\n",
    "    trainPaths = imagePaths[:trainPathsLen]\n",
    "    valPaths = imagePaths[trainPathsLen:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c85b143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7290008804189',\n",
       " '7290008670142',\n",
       " '7290000024264',\n",
       " '7290008670159',\n",
       " '7290015781015',\n",
       " '7290006256089',\n",
       " '7290014466609',\n",
       " '7290008802512',\n",
       " '7290015781114',\n",
       " '7290012576607',\n",
       " '7290015951227',\n",
       " '7290015781008',\n",
       " '7290008801843',\n",
       " '7290000023809',\n",
       " '7290015350150',\n",
       " '7290000023847']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
