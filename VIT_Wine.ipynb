{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d4a1ae2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import glob\n",
    "import pytorch_lightning as pl\n",
    "from huggingface_hub import HfApi, Repository\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchmetrics import Accuracy\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5832e4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"/home/orelit/Projects -Sathsara/Planigo/data/VIT_train_wine_low_variance_test_augmented\")\n",
    "\n",
    "ds=ImageFolder(data_dir)\n",
    "indices = torch.randperm(len(ds)).tolist()\n",
    "n_val = math.floor(len(indices) * .15)\n",
    "train_ds = torch.utils.data.Subset(ds, indices[:-n_val])\n",
    "val_ds = torch.utils.data.Subset(ds, indices[-n_val:])\n",
    "\n",
    "\n",
    "label2id = {}\n",
    "id2label = {}\n",
    "for i, class_name in enumerate(ds.classes):\n",
    "  label2id[class_name] = str(i)\n",
    "  id2label[str(i)] = class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ab42358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "class ImageClassificationCollator:\n",
    "   def __init__(self, feature_extractor): \n",
    "      self.feature_extractor = feature_extractor\n",
    "   def __call__(self, batch):  \n",
    "      encodings = self.feature_extractor([x[0] for x in batch],\n",
    "      return_tensors='pt')   \n",
    "      encodings['labels'] = torch.tensor([x[1] for x in batch],    \n",
    "      dtype=torch.long)\n",
    "      return encodings\n",
    "\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "collator = ImageClassificationCollator(feature_extractor)\n",
    "train_loader = DataLoader(train_ds, batch_size=32, \n",
    "   collate_fn=collator, num_workers=2, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=32, collate_fn=collator, \n",
    "   num_workers=2)\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "        'google/vit-base-patch16-224-in21k',\n",
    "         num_labels=len(label2id),\n",
    "         label2id=label2id,\n",
    "         id2label=id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a0b7a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(pl.LightningModule):\n",
    "   def __init__(self, model, lr: float = 2e-5, **kwargs): \n",
    "       super().__init__()\n",
    "       self.save_hyperparameters('lr', *list(kwargs))\n",
    "       self.model = model\n",
    "       self.forward = self.model.forward \n",
    "       self.val_acc = Accuracy()\n",
    "   def training_step(self, batch, batch_idx):\n",
    "       outputs = self(**batch)\n",
    "       self.log(f\"train_loss\", outputs.loss)\n",
    "       return outputs.loss\n",
    "   def validation_step(self, batch, batch_idx):\n",
    "       outputs = self(**batch)\n",
    "       self.log(f\"val_loss\", outputs.loss)\n",
    "       acc = self.val_acc(outputs.logits.argmax(1), batch['labels'])\n",
    "       self.log(f\"val_acc\", acc, prog_bar=True)\n",
    "       return outputs.loss\n",
    "   def configure_optimizers(self):\n",
    "       return torch.optim.Adam(self.parameters(), \n",
    "                        lr=self.hparams.lr,weight_decay = 0.00025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a9dfd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "/home/orelit/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type                      | Params\n",
      "------------------------------------------------------\n",
      "0 | model   | ViTForImageClassification | 85.8 M\n",
      "1 | val_acc | Accuracy                  | 0     \n",
      "------------------------------------------------------\n",
      "85.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "85.8 M    Total params\n",
      "171.622   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orelit/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/orelit/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca5583dcb16643fdb82b7b089deb9b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(42)\n",
    "classifier = Classifier(model, lr=2e-5)\n",
    "trainer = pl.Trainer(gpus=1, precision=16, max_epochs=10)\n",
    "trainer.fit(classifier, train_loader, val_loader)\n",
    "\n",
    "model.save_pretrained(\"/home/orelit/Projects -Sathsara/Planigo/Models/VIT_WINE/low_variance_augmented_data_10_epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e75512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3d36ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58a41a6f",
   "metadata": {},
   "source": [
    "# Hyper-parameter tuning for VIT with WandB Sweaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a38557d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msathsara_rasantha\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83e4e00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'random'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c46ba5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = {\n",
    "    'name': 'loss',\n",
    "    'goal': 'minimize'   \n",
    "    }\n",
    "\n",
    "sweep_config['metric'] = metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21e37166",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_dict = {\n",
    "    'optimizer': {\n",
    "        'values': ['adam', 'sgd']\n",
    "        },\n",
    "    'fc_layer_size': {\n",
    "        'values': [128, 256, 512]\n",
    "        },\n",
    "    'dropout': {\n",
    "          'values': [0.3, 0.4, 0.5]\n",
    "        },\n",
    "    }\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63045d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_dict.update({\n",
    "    'epochs': {\n",
    "        'value': 1}\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23497bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_dict.update({\n",
    "    'learning_rate': {\n",
    "        # a flat distribution between 0 and 0.1\n",
    "        'distribution': 'uniform',\n",
    "        'min': 0,\n",
    "        'max': 0.1\n",
    "      },\n",
    "    'batch_size': {\n",
    "        # integers between 32 and 256\n",
    "        # with evenly-distributed logarithms \n",
    "        'distribution': 'q_log_uniform_values',\n",
    "        'q': 8,\n",
    "        'min': 4,\n",
    "        'max': 32,\n",
    "      }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3ad9648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'random',\n",
      " 'metric': {'goal': 'minimize', 'name': 'loss'},\n",
      " 'parameters': {'batch_size': {'distribution': 'q_log_uniform_values',\n",
      "                               'max': 32,\n",
      "                               'min': 4,\n",
      "                               'q': 8},\n",
      "                'dropout': {'values': [0.3, 0.4, 0.5]},\n",
      "                'epochs': {'value': 1},\n",
      "                'fc_layer_size': {'values': [128, 256, 512]},\n",
      "                'learning_rate': {'distribution': 'uniform',\n",
      "                                  'max': 0.1,\n",
      "                                  'min': 0},\n",
      "                'optimizer': {'values': ['adam', 'sgd']}}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34e6cfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: wytqkv0x\n",
      "Sweep URL: https://wandb.ai/sathsara_rasantha/VIT-Wine-Hyper-parameter-tuning/sweeps/wytqkv0x\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"VIT-Wine-Hyper-parameter-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4df40ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e223498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bb34923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config=None):\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config):\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "        \n",
    "        feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "        collator = ImageClassificationCollator(feature_extractor)\n",
    "        train_loader = DataLoader(train_ds, batch_size=config.batch_size, \n",
    "             collate_fn=collator, num_workers=2, shuffle=True)\n",
    "        val_loader = DataLoader(val_ds, batch_size=config.batch_size, collate_fn=collator, \n",
    "             num_workers=2)\n",
    "        model = ViTForImageClassification.from_pretrained(\n",
    "                 'google/vit-base-patch16-224-in21k',\n",
    "                  num_labels=len(label2id),\n",
    "                  label2id=label2id,\n",
    "                  id2label=id2label)\n",
    "\n",
    "        classifier = Classifier(model, lr=config.learning_rate)\n",
    "        trainer = pl.Trainer(gpus=1, precision=16, max_epochs=config.epochs)\n",
    "        trainer.fit(classifier, train_loader, val_loader)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98f5db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 93k8se2r with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.08139950020932776\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/orelit/Projects -Sathsara/Planigo/wandb/run-20220923_150201-93k8se2r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sathsara_rasantha/VIT-Wine-Hyper-parameter-tuning/runs/93k8se2r\" target=\"_blank\">radiant-sweep-1</a></strong> to <a href=\"https://wandb.ai/sathsara_rasantha/VIT-Wine-Hyper-parameter-tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/sathsara_rasantha/VIT-Wine-Hyper-parameter-tuning/sweeps/wytqkv0x\" target=\"_blank\">https://wandb.ai/sathsara_rasantha/VIT-Wine-Hyper-parameter-tuning/sweeps/wytqkv0x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/orelit/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type                      | Params\n",
      "------------------------------------------------------\n",
      "0 | model   | ViTForImageClassification | 86.0 M\n",
      "1 | val_acc | Accuracy                  | 0     \n",
      "------------------------------------------------------\n",
      "86.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "86.0 M    Total params\n",
      "171.916   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orelit/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/orelit/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6beb24509b149078fda4eb9db5e8b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">radiant-sweep-1</strong>: <a href=\"https://wandb.ai/sathsara_rasantha/VIT-Wine-Hyper-parameter-tuning/runs/93k8se2r\" target=\"_blank\">https://wandb.ai/sathsara_rasantha/VIT-Wine-Hyper-parameter-tuning/runs/93k8se2r</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220923_150201-93k8se2r/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zk29gb06 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.03293916214026169\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/orelit/Projects -Sathsara/Planigo/wandb/run-20220923_151159-zk29gb06</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sathsara_rasantha/VIT-Wine-Hyper-parameter-tuning/runs/zk29gb06\" target=\"_blank\">gentle-sweep-2</a></strong> to <a href=\"https://wandb.ai/sathsara_rasantha/VIT-Wine-Hyper-parameter-tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/sathsara_rasantha/VIT-Wine-Hyper-parameter-tuning/sweeps/wytqkv0x\" target=\"_blank\">https://wandb.ai/sathsara_rasantha/VIT-Wine-Hyper-parameter-tuning/sweeps/wytqkv0x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/orelit/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type                      | Params\n",
      "------------------------------------------------------\n",
      "0 | model   | ViTForImageClassification | 86.0 M\n",
      "1 | val_acc | Accuracy                  | 0     \n",
      "------------------------------------------------------\n",
      "86.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "86.0 M    Total params\n",
      "171.916   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6403c72c5505422fa9e321f8c3df7f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">gentle-sweep-2</strong>: <a href=\"https://wandb.ai/sathsara_rasantha/VIT-Wine-Hyper-parameter-tuning/runs/zk29gb06\" target=\"_blank\">https://wandb.ai/sathsara_rasantha/VIT-Wine-Hyper-parameter-tuning/runs/zk29gb06</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220923_151159-zk29gb06/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qq9mv3e6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.09260322191459402\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/orelit/Projects -Sathsara/Planigo/wandb/run-20220923_152047-qq9mv3e6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sathsara_rasantha/VIT-Wine-Hyper-parameter-tuning/runs/qq9mv3e6\" target=\"_blank\">breezy-sweep-3</a></strong> to <a href=\"https://wandb.ai/sathsara_rasantha/VIT-Wine-Hyper-parameter-tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/sathsara_rasantha/VIT-Wine-Hyper-parameter-tuning/sweeps/wytqkv0x\" target=\"_blank\">https://wandb.ai/sathsara_rasantha/VIT-Wine-Hyper-parameter-tuning/sweeps/wytqkv0x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type                      | Params\n",
      "------------------------------------------------------\n",
      "0 | model   | ViTForImageClassification | 86.0 M\n",
      "1 | val_acc | Accuracy                  | 0     \n",
      "------------------------------------------------------\n",
      "86.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "86.0 M    Total params\n",
      "171.916   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3986d062087248f598234a77fcda1dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">breezy-sweep-3</strong>: <a href=\"https://wandb.ai/sathsara_rasantha/VIT-Wine-Hyper-parameter-tuning/runs/qq9mv3e6\" target=\"_blank\">https://wandb.ai/sathsara_rasantha/VIT-Wine-Hyper-parameter-tuning/runs/qq9mv3e6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220923_152047-qq9mv3e6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2ovhsts3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.05026258050569345\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/orelit/Projects -Sathsara/Planigo/wandb/run-20220923_152931-2ovhsts3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sathsara_rasantha/VIT-Wine-Hyper-parameter-tuning/runs/2ovhsts3\" target=\"_blank\">smart-sweep-4</a></strong> to <a href=\"https://wandb.ai/sathsara_rasantha/VIT-Wine-Hyper-parameter-tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/sathsara_rasantha/VIT-Wine-Hyper-parameter-tuning/sweeps/wytqkv0x\" target=\"_blank\">https://wandb.ai/sathsara_rasantha/VIT-Wine-Hyper-parameter-tuning/sweeps/wytqkv0x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type                      | Params\n",
      "------------------------------------------------------\n",
      "0 | model   | ViTForImageClassification | 86.0 M\n",
      "1 | val_acc | Accuracy                  | 0     \n",
      "------------------------------------------------------\n",
      "86.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "86.0 M    Total params\n",
      "171.916   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2bf684e7fa46bfb0e5f5525891164e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train, count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9425c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af47065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "960af958",
   "metadata": {},
   "source": [
    "# Model training with WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79837dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0207e8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(monitor='val_acc', mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4bec528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f45f927f534e5a982eedb88fecdf4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.03333678245544434, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20220927_115048-m8f09dlz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sathsara_rasantha/VIT_wine-trainig_with_PL_2022_09_27/runs/m8f09dlz\" target=\"_blank\">sunny-dream-3</a></strong> to <a href=\"https://wandb.ai/sathsara_rasantha/VIT_wine-trainig_with_PL_2022_09_27\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "wandb_logger = WandbLogger(project='VIT_wine-trainig_with_PL_2022_09_27', # group runs in \"MNIST\" project\n",
    "                           log_model='all') # log all new checkpoints during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "101f9bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type                      | Params\n",
      "------------------------------------------------------\n",
      "0 | model   | ViTForImageClassification | 86.0 M\n",
      "1 | val_acc | Accuracy                  | 0     \n",
      "------------------------------------------------------\n",
      "86.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "86.0 M    Total params\n",
      "171.916   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4deb240f8deb437b8401f7082f9001c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='983.953 MB of 983.953 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆████████</td></tr><tr><td>train_loss</td><td>██▇▅▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>██▁██</td></tr><tr><td>val_loss</td><td>█▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train_loss</td><td>0.01198</td></tr><tr><td>trainer/global_step</td><td>6669</td></tr><tr><td>val_acc</td><td>1.0</td></tr><tr><td>val_loss</td><td>0.01208</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">sunny-dream-3</strong>: <a href=\"https://wandb.ai/sathsara_rasantha/VIT_wine-trainig_with_PL_2022_09_27/runs/m8f09dlz\" target=\"_blank\">https://wandb.ai/sathsara_rasantha/VIT_wine-trainig_with_PL_2022_09_27/runs/m8f09dlz</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220927_115048-m8f09dlz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = Classifier(model, lr=2e-5)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1, \n",
    "    precision=16,\n",
    "    logger=wandb_logger,                   \n",
    "    callbacks=[checkpoint_callback],       \n",
    "    max_epochs=5) \n",
    "trainer.fit(classifier, train_loader, val_loader)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1f6a65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6b2e352",
   "metadata": {},
   "source": [
    "# Model Inferencing - VIT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96a62274",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/home/orelit/Projects -Sathsara/Planigo/Models/VIT_WINE/low_variance_augmented_data_5_epochs'\n",
    "wine_model = ViTForImageClassification.from_pretrained(\n",
    "         model_path,\n",
    "         num_labels=len(label2id),\n",
    "         label2id=label2id,\n",
    "         id2label=id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0301055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(img_path):\n",
    "   im=Image.open(img_path)\n",
    "   encoding = feature_extractor(images=im, return_tensors=\"pt\")\n",
    "   encoding.keys()\n",
    "   pixel_values = encoding['pixel_values']\n",
    "   outputs = wine_model(pixel_values)\n",
    "   result = outputs.logits.softmax(1).argmax(1)\n",
    "   tensor_result = outputs.logits.softmax(1)\n",
    "   prob = torch.max(tensor_result)\n",
    "   new_result = result.tolist() \n",
    "   for i in new_result:\n",
    "     return(id2label[str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90a1e4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProbs(img_path):\n",
    "   im=Image.open(img_path)\n",
    "   encoding = feature_extractor(images=im, return_tensors=\"pt\")\n",
    "   encoding.keys()\n",
    "   pixel_values = encoding['pixel_values']\n",
    "   outputs = model_new(pixel_values)\n",
    "   tensor_result = outputs.logits.softmax(1)\n",
    "   prob = torch.max(tensor_result)\n",
    "   return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8482861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_path):\n",
    "   pil_image = Image.open(image_path)\n",
    "   if pil_image.size[0] > pil_image.size[1]:\n",
    "       pil_image.thumbnail((5000, 256))\n",
    "   else:\n",
    "       pil_image.thumbnail((256, 5000))\n",
    "   left_margin = (pil_image.width-224)/2\n",
    "   bottom_margin = (pil_image.height-224)/2\n",
    "   right_margin = left_margin + 224\n",
    "   top_margin = bottom_margin + 224\n",
    "   pil_image = pil_image.crop((left_margin, bottom_margin, \n",
    "                               right_margin, top_margin))\n",
    "   np_image = np.array(pil_image)/255\n",
    "   mean = np.array([0.485, 0.456, 0.406])\n",
    "   std = np.array([0.229, 0.224, 0.225])\n",
    "   np_image = (np_image - mean) / std\n",
    "   np_image = np_image.transpose((2, 0, 1))\n",
    "   return np_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "325aa340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None):\n",
    "   if ax is None:\n",
    "      fig, ax = plt.subplots()\n",
    "   image = image.transpose((1, 2, 0))\n",
    "   mean = np.array([0.485, 0.456, 0.406])\n",
    "   std = np.array([0.229, 0.224, 0.225])\n",
    "   image = std * image + mean\n",
    "   if title is not None:\n",
    "      ax.set_title(title)\n",
    "   image = np.clip(image, 0, 1)\n",
    "   ax.imshow(image)\n",
    "   \n",
    "   return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f42dbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image_dir):\n",
    "   \n",
    "   plt.figure(figsize = (6,10))\n",
    "   plot_1 = plt.subplot(2,1,1)\n",
    "   image = process_image(image_dir)\n",
    "   asl_sign = image_dir[image_dir.rfind('/')+1:]\n",
    "   pred= prediction(image_dir)\n",
    "   plot_1.set_xlabel(\"The predicted sign: \"+pred)\n",
    "   imshow(image, plot_1, title=asl_sign);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0716a1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# image_path1 = '/home/orelit/Projects -Sathsara/Planigo/data/VIT_test/4022025001905 (2).jpeg'\n",
    "# display_image(image_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7acbbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction(image_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cc82776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "test_data_path = '/home/orelit/Projects -Sathsara/Planigo/data/VIT_test_wine_low_variance_test/All_barcodes'\n",
    "\n",
    "image_paths = []\n",
    "for image in os.listdir(test_data_path):\n",
    "    img = test_data_path +'/'+image\n",
    "    image_paths.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eed75a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in image_paths:\n",
    "#     display_image(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2de38ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_label = image_path1[image_path1.rfind('/')+1:]\n",
    "# test_label\n",
    "# test_label = re.sub(r'\\([^)]*\\)', '', test_label)\n",
    "# x = test_label.split(\" \")\n",
    "\n",
    "# if len(x)>1:\n",
    "#     final_output = x[0]\n",
    "# else:\n",
    "#     y = test_label.split(\".\")\n",
    "#     final_output = y[0]\n",
    "    \n",
    "# final_output\n",
    "# test_label[0:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1b568f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction :  7290000023847\n",
      "Real Label :  7290008670142\n",
      "Misclassified\n",
      ".....................................\n",
      "Prediction :  7290008801843\n",
      "Real Label :  7290008801843\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290000024264\n",
      "Real Label :  7290000024264\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290015781008\n",
      "Real Label :  7290015350150\n",
      "Misclassified\n",
      ".....................................\n",
      "Prediction :  7290015781008\n",
      "Real Label :  7290015350150\n",
      "Misclassified\n",
      ".....................................\n",
      "Prediction :  7290000023847\n",
      "Real Label :  7290000023847\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290012576607\n",
      "Real Label :  7290012576607\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290000024264\n",
      "Real Label :  7290000024264\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290015781008\n",
      "Real Label :  7290015350150\n",
      "Misclassified\n",
      ".....................................\n",
      "Prediction :  7290000024264\n",
      "Real Label :  7290000024264\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290000024264\n",
      "Real Label :  7290000023809\n",
      "Misclassified\n",
      ".....................................\n",
      "Prediction :  7290006256089\n",
      "Real Label :  7290006256089\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290015951227\n",
      "Real Label :  7290015951227\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290015781008\n",
      "Real Label :  7290015781008\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290006256089\n",
      "Real Label :  7290006256089\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290008801843\n",
      "Real Label :  7290008801843\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290015781114\n",
      "Real Label :  7290015781114\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290000024264\n",
      "Real Label :  7290008801843\n",
      "Misclassified\n",
      ".....................................\n",
      "Prediction :  7290012576607\n",
      "Real Label :  7290000023809\n",
      "Misclassified\n",
      ".....................................\n",
      "Prediction :  7290015781114\n",
      "Real Label :  7290015781114\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290008670159\n",
      "Real Label :  7290008670159\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290008804189\n",
      "Real Label :  7290008804189\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290008802512\n",
      "Real Label :  7290008802512\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290006256089\n",
      "Real Label :  7290006256089\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290000024264\n",
      "Real Label :  7290000024264\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290015781008\n",
      "Real Label :  7290015781015\n",
      "Misclassified\n",
      ".....................................\n",
      "Prediction :  7290014466609\n",
      "Real Label :  7290014466609\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290012576607\n",
      "Real Label :  7290012576607\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290008670159\n",
      "Real Label :  7290008670159\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290015350150\n",
      "Real Label :  7290015350150\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290008802512\n",
      "Real Label :  7290008802512\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290015781008\n",
      "Real Label :  7290015781015\n",
      "Misclassified\n",
      ".....................................\n",
      "Prediction :  7290000024264\n",
      "Real Label :  7290000023809\n",
      "Misclassified\n",
      ".....................................\n",
      "Prediction :  7290008801843\n",
      "Real Label :  7290008801843\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290008804189\n",
      "Real Label :  7290008804189\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290012576607\n",
      "Real Label :  7290012576607\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290006256089\n",
      "Real Label :  7290006256089\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290015781008\n",
      "Real Label :  7290015350150\n",
      "Misclassified\n",
      ".....................................\n",
      "Prediction :  7290015350150\n",
      "Real Label :  7290015350150\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290015951227\n",
      "Real Label :  7290015951227\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290015781114\n",
      "Real Label :  7290015781114\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290008670159\n",
      "Real Label :  7290008670159\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290015951227\n",
      "Real Label :  7290015951227\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290012576607\n",
      "Real Label :  7290012576607\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290015350150\n",
      "Real Label :  7290015350150\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290015781008\n",
      "Real Label :  7290015350150\n",
      "Misclassified\n",
      ".....................................\n",
      "Prediction :  7290000023847\n",
      "Real Label :  7290008670142\n",
      "Misclassified\n",
      ".....................................\n",
      "Prediction :  7290008802512\n",
      "Real Label :  7290008802512\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290000023847\n",
      "Real Label :  7290000023847\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290015781008\n",
      "Real Label :  7290015781008\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290015781008\n",
      "Real Label :  7290015781015\n",
      "Misclassified\n",
      ".....................................\n",
      "Prediction :  7290000024264\n",
      "Real Label :  7290000023809\n",
      "Misclassified\n",
      ".....................................\n",
      "Prediction :  7290008670159\n",
      "Real Label :  7290008670159\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290008802512\n",
      "Real Label :  7290008802512\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290000023847\n",
      "Real Label :  7290000023847\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290000024264\n",
      "Real Label :  7290008801843\n",
      "Misclassified\n",
      ".....................................\n",
      "Prediction :  7290015951227\n",
      "Real Label :  7290015951227\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290015781008\n",
      "Real Label :  7290015781008\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290015781114\n",
      "Real Label :  7290015781114\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290000024264\n",
      "Real Label :  7290008801843\n",
      "Misclassified\n",
      ".....................................\n",
      "Prediction :  7290006256089\n",
      "Real Label :  7290006256089\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290008801843\n",
      "Real Label :  7290008801843\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290000024264\n",
      "Real Label :  7290000024264\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290000024264\n",
      "Real Label :  7290000024264\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290008670159\n",
      "Real Label :  7290008670159\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Prediction :  7290015350150\n",
      "Real Label :  7290015350150\n",
      "Correctly Classified\n",
      ".....................................\n",
      "Number of images :  66\n",
      "Number of correctly classified images :  49\n",
      "Accuray :  0.7424242424242424\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "count = 0\n",
    "correct = 0\n",
    "for image in os.listdir(test_data_path):\n",
    "    img = test_data_path +'/'+image\n",
    "    pred= prediction(img)\n",
    "    print('Prediction : ',pred)\n",
    "    test_label = image[image.rfind('/')+1:]\n",
    "    real_class = test_label[0:13]\n",
    "    print('Real Label : ',real_class)\n",
    "    if real_class == pred:\n",
    "        correct = correct +1\n",
    "        print('Correctly Classified')\n",
    "    else:\n",
    "        print('Misclassified')\n",
    "    count = count + 1\n",
    "    print('.....................................')\n",
    "    \n",
    "acc = correct/count\n",
    "print(\"Number of images : \",count)\n",
    "print(\"Number of correctly classified images : \",correct)\n",
    "print(\"Accuray : \",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d0c3d1",
   "metadata": {},
   "source": [
    "# Wine Models Inferencing with multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31b7ea25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>model4</th>\n",
       "      <th>model5</th>\n",
       "      <th>model6</th>\n",
       "      <th>model7</th>\n",
       "      <th>model8</th>\n",
       "      <th>model9</th>\n",
       "      <th>model10</th>\n",
       "      <th>model11</th>\n",
       "      <th>model12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73490154317</td>\n",
       "      <td>3760125946870</td>\n",
       "      <td>4022025001905</td>\n",
       "      <td>4022025002100</td>\n",
       "      <td>4022025290408</td>\n",
       "      <td>5998623530644</td>\n",
       "      <td>7290000024202</td>\n",
       "      <td>7290000024264</td>\n",
       "      <td>4001432773230</td>\n",
       "      <td>4022025001929</td>\n",
       "      <td>4022025261002</td>\n",
       "      <td>608614309160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3760125946719</td>\n",
       "      <td>608614309269</td>\n",
       "      <td>608614309290</td>\n",
       "      <td>7290004494063</td>\n",
       "      <td>7290000023809</td>\n",
       "      <td>7290000023977</td>\n",
       "      <td>7290008836265</td>\n",
       "      <td>7290014256620</td>\n",
       "      <td>7290015781008</td>\n",
       "      <td>7290008804332</td>\n",
       "      <td>7290006696717</td>\n",
       "      <td>7290006256089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>608614309184</td>\n",
       "      <td>7290000023847</td>\n",
       "      <td>7290000024219</td>\n",
       "      <td>7290008801157</td>\n",
       "      <td>7290000024530</td>\n",
       "      <td>7290000521022</td>\n",
       "      <td>7290015951227</td>\n",
       "      <td>7290015781145</td>\n",
       "      <td>7290016607772</td>\n",
       "      <td>7290014503137</td>\n",
       "      <td>7290014501232</td>\n",
       "      <td>7290010298273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7290000023816</td>\n",
       "      <td>7290000521008</td>\n",
       "      <td>7290005966088</td>\n",
       "      <td>7290008801850</td>\n",
       "      <td>7290004658953</td>\n",
       "      <td>7290004658946</td>\n",
       "      <td>7290017812847</td>\n",
       "      <td>7290017812618</td>\n",
       "      <td>7290017812588</td>\n",
       "      <td>7290101582397</td>\n",
       "      <td>7290018165027</td>\n",
       "      <td>7290017004457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7290000024554</td>\n",
       "      <td>7290006256102</td>\n",
       "      <td>7290008670159</td>\n",
       "      <td>7290008803014</td>\n",
       "      <td>7290008801843</td>\n",
       "      <td>7290008802291</td>\n",
       "      <td>7290108620214</td>\n",
       "      <td>7290103681630</td>\n",
       "      <td>8422443005213</td>\n",
       "      <td>8002450206003</td>\n",
       "      <td>8002450206508</td>\n",
       "      <td>7290108620153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7290000521404</td>\n",
       "      <td>7290006696595</td>\n",
       "      <td>7290008670678</td>\n",
       "      <td>7290008807777</td>\n",
       "      <td>7290008804462</td>\n",
       "      <td>7290008807029</td>\n",
       "      <td>7290004494353</td>\n",
       "      <td>7290004494049</td>\n",
       "      <td>7290000024516</td>\n",
       "      <td>7290000024240</td>\n",
       "      <td>4603400000043</td>\n",
       "      <td>608614309245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7290002363491</td>\n",
       "      <td>7290008670142</td>\n",
       "      <td>7290008801010</td>\n",
       "      <td>7290008836272</td>\n",
       "      <td>7290008805384</td>\n",
       "      <td>7290008836425</td>\n",
       "      <td>7290008836494</td>\n",
       "      <td>7290014910461</td>\n",
       "      <td>7290015781138</td>\n",
       "      <td>7290010656615</td>\n",
       "      <td>7290008804189</td>\n",
       "      <td>7290008801461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7290004494131</td>\n",
       "      <td>7290008670302</td>\n",
       "      <td>7290008802512</td>\n",
       "      <td>7290008921176</td>\n",
       "      <td>7290008836401</td>\n",
       "      <td>7290014501829</td>\n",
       "      <td>7290017647425</td>\n",
       "      <td>7290016717235</td>\n",
       "      <td>7290017589763</td>\n",
       "      <td>7290015781107</td>\n",
       "      <td>7290015781046</td>\n",
       "      <td>7290012576607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7290006256775</td>\n",
       "      <td>7290008801119</td>\n",
       "      <td>7290008802529</td>\n",
       "      <td>7290008921336</td>\n",
       "      <td>7290008921329</td>\n",
       "      <td>7290015350150</td>\n",
       "      <td>7290018165294</td>\n",
       "      <td>7290017812663</td>\n",
       "      <td>7290018165010</td>\n",
       "      <td>7290108620054</td>\n",
       "      <td>7290101582403</td>\n",
       "      <td>7290018165034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7290008801478</td>\n",
       "      <td>7290008801539</td>\n",
       "      <td>7290008803021</td>\n",
       "      <td>7290014466128</td>\n",
       "      <td>7290014466135</td>\n",
       "      <td>7290017589633</td>\n",
       "      <td>7290008802895</td>\n",
       "      <td>7290004494315</td>\n",
       "      <td>7290005966033</td>\n",
       "      <td>7290000484747</td>\n",
       "      <td>608614309276</td>\n",
       "      <td>7290000024523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7290008801546</td>\n",
       "      <td>7290008805964</td>\n",
       "      <td>7290008804745</td>\n",
       "      <td>7290015781114</td>\n",
       "      <td>7290015350136</td>\n",
       "      <td>7290017589848</td>\n",
       "      <td>7290010173037</td>\n",
       "      <td>7290015350402</td>\n",
       "      <td>7290015781299</td>\n",
       "      <td>7290014466463</td>\n",
       "      <td>7290012576423</td>\n",
       "      <td>7290008803090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7290008805520</td>\n",
       "      <td>7290015348423</td>\n",
       "      <td>7290015350143</td>\n",
       "      <td>7290017289120</td>\n",
       "      <td>7290015781121</td>\n",
       "      <td>7290017812885</td>\n",
       "      <td>7290017647708</td>\n",
       "      <td>7290017289601</td>\n",
       "      <td>7290017647548</td>\n",
       "      <td>7290016717051</td>\n",
       "      <td>7290015781091</td>\n",
       "      <td>7290012576614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7290014503144</td>\n",
       "      <td>7290016717976</td>\n",
       "      <td>7290016717099</td>\n",
       "      <td>7290017589923</td>\n",
       "      <td>7290017289175</td>\n",
       "      <td>7290017812977</td>\n",
       "      <td>7290018294192</td>\n",
       "      <td>7290018294208</td>\n",
       "      <td>7798141877829</td>\n",
       "      <td>7804414000877</td>\n",
       "      <td>7290108620061</td>\n",
       "      <td>7290103681371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7290017289106</td>\n",
       "      <td>7290017289205</td>\n",
       "      <td>7290017289199</td>\n",
       "      <td>7290017647722</td>\n",
       "      <td>7290017812069</td>\n",
       "      <td>7290018165560</td>\n",
       "      <td>7290008804455</td>\n",
       "      <td>7290010656592</td>\n",
       "      <td>7290014256637</td>\n",
       "      <td>7290004494377</td>\n",
       "      <td>7290004494919</td>\n",
       "      <td>7290004494148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7290017289168</td>\n",
       "      <td>7290018294000</td>\n",
       "      <td>7290017589565</td>\n",
       "      <td>7290103681210</td>\n",
       "      <td>7290017812656</td>\n",
       "      <td>7290103681364</td>\n",
       "      <td>7290014501942</td>\n",
       "      <td>7290015781015</td>\n",
       "      <td>7290015951869</td>\n",
       "      <td>7290014501331</td>\n",
       "      <td>7290014466609</td>\n",
       "      <td>7290010173044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7290017289182</td>\n",
       "      <td>7290101582373</td>\n",
       "      <td>7290103681180</td>\n",
       "      <td>7290108620085</td>\n",
       "      <td>7290103681388</td>\n",
       "      <td>7290103681395</td>\n",
       "      <td>7290017812830</td>\n",
       "      <td>7290017812052</td>\n",
       "      <td>7290017812571</td>\n",
       "      <td>7290018165959</td>\n",
       "      <td>7290016717754</td>\n",
       "      <td>7290016717631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7290100944462</td>\n",
       "      <td>8002450206522</td>\n",
       "      <td>7804414000884</td>\n",
       "      <td>7290108620115</td>\n",
       "      <td>7290108620108</td>\n",
       "      <td>8002450208007</td>\n",
       "      <td>7290108620177</td>\n",
       "      <td>7290101582366</td>\n",
       "      <td>7804414001621</td>\n",
       "      <td>7804414017134</td>\n",
       "      <td>7804414000860</td>\n",
       "      <td>7290108620092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8002450204009</td>\n",
       "      <td>8412168002529</td>\n",
       "      <td>7804414012368</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model1         model2         model3         model4         model5  \\\n",
       "0     73490154317  3760125946870  4022025001905  4022025002100  4022025290408   \n",
       "1   3760125946719   608614309269   608614309290  7290004494063  7290000023809   \n",
       "2    608614309184  7290000023847  7290000024219  7290008801157  7290000024530   \n",
       "3   7290000023816  7290000521008  7290005966088  7290008801850  7290004658953   \n",
       "4   7290000024554  7290006256102  7290008670159  7290008803014  7290008801843   \n",
       "5   7290000521404  7290006696595  7290008670678  7290008807777  7290008804462   \n",
       "6   7290002363491  7290008670142  7290008801010  7290008836272  7290008805384   \n",
       "7   7290004494131  7290008670302  7290008802512  7290008921176  7290008836401   \n",
       "8   7290006256775  7290008801119  7290008802529  7290008921336  7290008921329   \n",
       "9   7290008801478  7290008801539  7290008803021  7290014466128  7290014466135   \n",
       "10  7290008801546  7290008805964  7290008804745  7290015781114  7290015350136   \n",
       "11  7290008805520  7290015348423  7290015350143  7290017289120  7290015781121   \n",
       "12  7290014503144  7290016717976  7290016717099  7290017589923  7290017289175   \n",
       "13  7290017289106  7290017289205  7290017289199  7290017647722  7290017812069   \n",
       "14  7290017289168  7290018294000  7290017589565  7290103681210  7290017812656   \n",
       "15  7290017289182  7290101582373  7290103681180  7290108620085  7290103681388   \n",
       "16  7290100944462  8002450206522  7804414000884  7290108620115  7290108620108   \n",
       "17  8002450204009  8412168002529  7804414012368           None           None   \n",
       "\n",
       "           model6         model7         model8         model9        model10  \\\n",
       "0   5998623530644  7290000024202  7290000024264  4001432773230  4022025001929   \n",
       "1   7290000023977  7290008836265  7290014256620  7290015781008  7290008804332   \n",
       "2   7290000521022  7290015951227  7290015781145  7290016607772  7290014503137   \n",
       "3   7290004658946  7290017812847  7290017812618  7290017812588  7290101582397   \n",
       "4   7290008802291  7290108620214  7290103681630  8422443005213  8002450206003   \n",
       "5   7290008807029  7290004494353  7290004494049  7290000024516  7290000024240   \n",
       "6   7290008836425  7290008836494  7290014910461  7290015781138  7290010656615   \n",
       "7   7290014501829  7290017647425  7290016717235  7290017589763  7290015781107   \n",
       "8   7290015350150  7290018165294  7290017812663  7290018165010  7290108620054   \n",
       "9   7290017589633  7290008802895  7290004494315  7290005966033  7290000484747   \n",
       "10  7290017589848  7290010173037  7290015350402  7290015781299  7290014466463   \n",
       "11  7290017812885  7290017647708  7290017289601  7290017647548  7290016717051   \n",
       "12  7290017812977  7290018294192  7290018294208  7798141877829  7804414000877   \n",
       "13  7290018165560  7290008804455  7290010656592  7290014256637  7290004494377   \n",
       "14  7290103681364  7290014501942  7290015781015  7290015951869  7290014501331   \n",
       "15  7290103681395  7290017812830  7290017812052  7290017812571  7290018165959   \n",
       "16  8002450208007  7290108620177  7290101582366  7804414001621  7804414017134   \n",
       "17           None           None           None           None           None   \n",
       "\n",
       "          model11        model12  \n",
       "0   4022025261002   608614309160  \n",
       "1   7290006696717  7290006256089  \n",
       "2   7290014501232  7290010298273  \n",
       "3   7290018165027  7290017004457  \n",
       "4   8002450206508  7290108620153  \n",
       "5   4603400000043   608614309245  \n",
       "6   7290008804189  7290008801461  \n",
       "7   7290015781046  7290012576607  \n",
       "8   7290101582403  7290018165034  \n",
       "9    608614309276  7290000024523  \n",
       "10  7290012576423  7290008803090  \n",
       "11  7290015781091  7290012576614  \n",
       "12  7290108620061  7290103681371  \n",
       "13  7290004494919  7290004494148  \n",
       "14  7290014466609  7290010173044  \n",
       "15  7290016717754  7290016717631  \n",
       "16  7804414000860  7290108620092  \n",
       "17           None           None  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "model_lists = []\n",
    "for i in range(12):\n",
    "    my_file = open(\"/home/orelit/Projects -Sathsara/Planigo/Models/wine_sections_text/model{}.txt\".format(i+1)\n",
    "                   , \"r\")\n",
    "    content = my_file.read()\n",
    "    x = content.split('\\n')\n",
    "    new_list = []\n",
    "    for item in x:\n",
    "        try:\n",
    "            new_item = int(item)\n",
    "            new_str = str(new_item)\n",
    "            new_list.append(new_str)\n",
    "        except:\n",
    "            pass\n",
    "    model_lists.append(new_list)\n",
    "    \n",
    "model_lists[0]\n",
    "\n",
    "model_dict = {'model1':model_lists[0],'model2':model_lists[1],'model3':model_lists[2],'model4':model_lists[3],\n",
    "              'model5':model_lists[4],'model6':model_lists[5],'model7':model_lists[6],'model8':model_lists[7],\n",
    "              'model9':model_lists[8],'model10':model_lists[9],'model11':model_lists[10],'model12':model_lists[11]}\n",
    "\n",
    "df = pd.DataFrame.from_dict(model_dict, orient='index').T\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21d0222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "test_data_path = '/home/orelit/Projects -Sathsara/Planigo/data/test'\n",
    "\n",
    "folder_names = []\n",
    "for folder in os.listdir(test_data_path):\n",
    "    folder_names.append(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46defe16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder name : 7290017289106\n",
      "model name : model1\n",
      "image name :  7290017289106 (2).jpeg\n",
      "predicted label :  7290017289106\n",
      "real label :  7290017289106\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290017289106 (1).jpeg\n",
      "predicted label :  7290017289106\n",
      "real label :  7290017289106\n",
      "Correctly classified\n",
      "..........................................\n",
      "folder name : 7290108620061\n",
      "model name : model11\n",
      "image name :  7290108620061.jpeg\n",
      "predicted label :  7290004494919\n",
      "real label :  7290108620061\n",
      "..........................................\n",
      "folder name : 7290017289199\n",
      "model name : model3\n",
      "image name :  7290017289199.jpeg\n",
      "predicted label :  7290015350143\n",
      "real label :  7290017289199\n",
      "..........................................\n",
      "folder name : 7290012576614\n",
      "model name : model12\n",
      "image name :  7290012576614 (1).jpeg\n",
      "predicted label :  7290012576614\n",
      "real label :  7290012576614\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290012576614 (3).jpeg\n",
      "predicted label :  7290012576614\n",
      "real label :  7290012576614\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290012576614 (2).jpeg\n",
      "predicted label :  7290012576614\n",
      "real label :  7290012576614\n",
      "Correctly classified\n",
      "..........................................\n",
      "folder name : 7290015781046\n",
      "model name : model11\n",
      "image name :  7290015781046 (1).jpeg\n",
      "predicted label :  7290004494919\n",
      "real label :  7290015781046\n",
      "..........................................\n",
      "image name :  7290015781046 (2).jpeg\n",
      "predicted label :  7290004494919\n",
      "real label :  7290015781046\n",
      "..........................................\n",
      "image name :  7290015781046 (3).jpeg\n",
      "predicted label :  7290004494919\n",
      "real label :  7290015781046\n",
      "..........................................\n",
      "folder name : 7290017812052\n",
      "model name : model8\n",
      "image name :  7290017812052 (3).jpeg\n",
      "predicted label :  7290000024264\n",
      "real label :  7290017812052\n",
      "..........................................\n",
      "image name :  7290017812052 (4).jpeg\n",
      "predicted label :  7290000024264\n",
      "real label :  7290017812052\n",
      "..........................................\n",
      "image name :  7290017812052 (1).jpeg\n",
      "predicted label :  7290000024264\n",
      "real label :  7290017812052\n",
      "..........................................\n",
      "image name :  7290017812052 (2).jpeg\n",
      "predicted label :  7290000024264\n",
      "real label :  7290017812052\n",
      "..........................................\n",
      "folder name : 7290008801119\n",
      "model name : model2\n",
      "image name :  7290008801119 (2).jpeg\n",
      "predicted label :  8412168002529\n",
      "real label :  7290008801119\n",
      "..........................................\n",
      "image name :  7290008801119 (1).jpeg\n",
      "predicted label :  7290017289205\n",
      "real label :  7290008801119\n",
      "..........................................\n",
      "folder name : 7290017289175\n",
      "model name : model5\n",
      "image name :  7290017289175 (6).jpeg\n",
      "predicted label :  7290015781121\n",
      "real label :  7290017289175\n",
      "..........................................\n",
      "image name :  7290017289175 (4).jpeg\n",
      "predicted label :  7290015781121\n",
      "real label :  7290017289175\n",
      "..........................................\n",
      "image name :  7290017289175 (5).jpeg\n",
      "predicted label :  7290015781121\n",
      "real label :  7290017289175\n",
      "..........................................\n",
      "image name :  7290017289175 (3).jpeg\n",
      "predicted label :  7290015781121\n",
      "real label :  7290017289175\n",
      "..........................................\n",
      "image name :  7290017289175 (1).jpeg\n",
      "predicted label :  7290015781121\n",
      "real label :  7290017289175\n",
      "..........................................\n",
      "image name :  7290017289175 (2).jpeg\n",
      "predicted label :  7290015781121\n",
      "real label :  7290017289175\n",
      "..........................................\n",
      "folder name : 7290108620177\n",
      "model name : model7\n",
      "image name :  7290108620177.jpeg\n",
      "predicted label :  7290008836494\n",
      "real label :  7290108620177\n",
      "..........................................\n",
      "folder name : 7290008805520\n",
      "model name : model1\n",
      "image name :  7290008805520 (3).jpeg\n",
      "predicted label :  7290017289106\n",
      "real label :  7290008805520\n",
      "..........................................\n",
      "image name :  7290008805520 (1).jpeg\n",
      "predicted label :  7290017289106\n",
      "real label :  7290008805520\n",
      "..........................................\n",
      "image name :  7290008805520 (2).jpeg\n",
      "predicted label :  7290017289168\n",
      "real label :  7290008805520\n",
      "..........................................\n",
      "folder name : 7290108620085\n",
      "model name : model4\n",
      "image name :  7290108620085 (1).jpeg\n",
      "predicted label :  7290103681210\n",
      "real label :  7290108620085\n",
      "..........................................\n",
      "image name :  7290108620085 (2).jpeg\n",
      "predicted label :  7290103681210\n",
      "real label :  7290108620085\n",
      "..........................................\n",
      "folder name : 7290005966033\n",
      "model name : model9\n",
      "image name :  7290005966033 (2).jpeg\n",
      "predicted label :  7290000024516\n",
      "real label :  7290005966033\n",
      "..........................................\n",
      "image name :  7290005966033 (1).jpeg\n",
      "predicted label :  7290000024516\n",
      "real label :  7290005966033\n",
      "..........................................\n",
      "folder name : 7290018294192\n",
      "model name : model7\n",
      "image name :  7290018294192 (4).jpeg\n",
      "predicted label :  7290008836494\n",
      "real label :  7290018294192\n",
      "..........................................\n",
      "image name :  7290018294192 (2).jpeg\n",
      "predicted label :  7290008836494\n",
      "real label :  7290018294192\n",
      "..........................................\n",
      "image name :  7290018294192 (3).jpeg\n",
      "predicted label :  7290008836494\n",
      "real label :  7290018294192\n",
      "..........................................\n",
      "image name :  7290018294192 (1).jpeg\n",
      "predicted label :  7290008836494\n",
      "real label :  7290018294192\n",
      "..........................................\n",
      "folder name : 7290008804189\n",
      "model name : model11\n",
      "image name :  7290008804189 (2).jpeg\n",
      "predicted label :  7804414000860\n",
      "real label :  7290008804189\n",
      "..........................................\n",
      "image name :  7290008804189 (1).jpeg\n",
      "predicted label :  7804414000860\n",
      "real label :  7290008804189\n",
      "..........................................\n",
      "folder name : 7290008670142\n",
      "model name : model2\n",
      "image name :  7290008670142 (2).jpeg\n",
      "predicted label :  7290017289205\n",
      "real label :  7290008670142\n",
      "..........................................\n",
      "image name :  7290008670142 (1).jpeg\n",
      "predicted label :  7290017289205\n",
      "real label :  7290008670142\n",
      "..........................................\n",
      "folder name : 7290108620214\n",
      "model name : model7\n",
      "image name :  7290108620214.jpeg\n",
      "predicted label :  7290008836494\n",
      "real label :  7290108620214\n",
      "..........................................\n",
      "folder name : 7290000024264\n",
      "model name : model8\n",
      "image name :  7290000024264 (4).jpeg\n",
      "predicted label :  7290000024264\n",
      "real label :  7290000024264\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290000024264 (1).jpeg\n",
      "predicted label :  7290000024264\n",
      "real label :  7290000024264\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290000024264 (6).jpeg\n",
      "predicted label :  7290000024264\n",
      "real label :  7290000024264\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290000024264 (2).jpeg\n",
      "predicted label :  7290000024264\n",
      "real label :  7290000024264\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290000024264 (5).jpeg\n",
      "predicted label :  7290000024264\n",
      "real label :  7290000024264\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290000024264 (3).jpeg\n",
      "predicted label :  7290000024264\n",
      "real label :  7290000024264\n",
      "Correctly classified\n",
      "..........................................\n",
      "folder name : 7290017289168\n",
      "model name : model1\n",
      "image name :  7290017289168.jpeg\n",
      "predicted label :  7290017289168\n",
      "real label :  7290017289168\n",
      "Correctly classified\n",
      "..........................................\n",
      "folder name : 7290018165027\n",
      "model name : model11\n",
      "image name :  7290018165027 (2).jpeg\n",
      "predicted label :  7290018165027\n",
      "real label :  7290018165027\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290018165027 (1).jpeg\n",
      "predicted label :  7290018165027\n",
      "real label :  7290018165027\n",
      "Correctly classified\n",
      "..........................................\n",
      "folder name : 722242877829\n",
      "model name : model11\n",
      "image name :  722242877829.jpeg\n",
      "predicted label :  7290004494919\n",
      "real label :  722242877829.\n",
      "..........................................\n",
      "folder name : 7290008670159\n",
      "model name : model3\n",
      "image name :  7290008670159 (1).jpeg\n",
      "predicted label :  7290008670159\n",
      "real label :  7290008670159\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290008670159 (5).jpeg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted label :  7290008670159\n",
      "real label :  7290008670159\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290008670159 (3).jpeg\n",
      "predicted label :  7290008670159\n",
      "real label :  7290008670159\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290008670159 (2).jpeg\n",
      "predicted label :  7290008670159\n",
      "real label :  7290008670159\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290008670159 (4).jpeg\n",
      "predicted label :  7290008670159\n",
      "real label :  7290008670159\n",
      "Correctly classified\n",
      "..........................................\n",
      "folder name : 7290015781015\n",
      "model name : model8\n",
      "image name :  7290015781015 (2).jpeg\n",
      "predicted label :  7290000024264\n",
      "real label :  7290015781015\n",
      "..........................................\n",
      "image name :  7290015781015 (3).jpeg\n",
      "predicted label :  7290000024264\n",
      "real label :  7290015781015\n",
      "..........................................\n",
      "image name :  7290015781015 (1).jpeg\n",
      "predicted label :  7290000024264\n",
      "real label :  7290015781015\n",
      "..........................................\n",
      "folder name : 7290018165447\n",
      "model name : model8\n",
      "image name :  7290018165447 (9).jpeg\n",
      "predicted label :  7290000024264\n",
      "real label :  7290018165447\n",
      "..........................................\n",
      "image name :  7290018165447 (1).jpeg\n",
      "predicted label :  7290000024264\n",
      "real label :  7290018165447\n",
      "..........................................\n",
      "image name :  7290018165447 (4).jpeg\n",
      "predicted label :  7290000024264\n",
      "real label :  7290018165447\n",
      "..........................................\n",
      "image name :  7290018165447 (7).jpeg\n",
      "predicted label :  7290000024264\n",
      "real label :  7290018165447\n",
      "..........................................\n",
      "image name :  7290018165447 (5).jpeg\n",
      "predicted label :  7290000024264\n",
      "real label :  7290018165447\n",
      "..........................................\n",
      "image name :  7290018165447 (6).jpeg\n",
      "predicted label :  7290000024264\n",
      "real label :  7290018165447\n",
      "..........................................\n",
      "image name :  7290018165447 (3).jpeg\n",
      "predicted label :  7290000024264\n",
      "real label :  7290018165447\n",
      "..........................................\n",
      "image name :  7290018165447 (2).jpeg\n",
      "predicted label :  7290000024264\n",
      "real label :  7290018165447\n",
      "..........................................\n",
      "image name :  7290018165447 (8).jpeg\n",
      "predicted label :  7290000024264\n",
      "real label :  7290018165447\n",
      "..........................................\n",
      "folder name : 7290008802529\n",
      "model name : model3\n",
      "image name :  7290008802529 (2).jpeg\n",
      "predicted label :  7290008670159\n",
      "real label :  7290008802529\n",
      "..........................................\n",
      "image name :  7290008802529 (3).jpeg\n",
      "predicted label :  7290015350143\n",
      "real label :  7290008802529\n",
      "..........................................\n",
      "image name :  7290008802529 (1).jpeg\n",
      "predicted label :  7290015350143\n",
      "real label :  7290008802529\n",
      "..........................................\n",
      "image name :  7290008802529 (4).jpeg\n",
      "predicted label :  7290015350143\n",
      "real label :  7290008802529\n",
      "..........................................\n",
      "folder name : 4022025001905\n",
      "model name : model3\n",
      "image name :  4022025001905 (1).jpeg\n",
      "predicted label :  7290017589565\n",
      "real label :  4022025001905\n",
      "..........................................\n",
      "image name :  4022025001905 (2).jpeg\n",
      "predicted label :  7290017589565\n",
      "real label :  4022025001905\n",
      "..........................................\n",
      "folder name : 7290000024554\n",
      "model name : model1\n",
      "image name :  7290000024554 (2).jpeg\n",
      "predicted label :  8002450204009\n",
      "real label :  7290000024554\n",
      "..........................................\n",
      "image name :  7290000024554 (1).jpeg\n",
      "predicted label :  8002450204009\n",
      "real label :  7290000024554\n",
      "..........................................\n",
      "image name :  7290000024554 (3).jpeg\n",
      "predicted label :  8002450204009\n",
      "real label :  7290000024554\n",
      "..........................................\n",
      "image name :  7290000024554 (4).jpeg\n",
      "predicted label :  8002450204009\n",
      "real label :  7290000024554\n",
      "..........................................\n",
      "folder name : 7290017812847\n",
      "model name : model7\n",
      "image name :  7290017812847 (1).jpeg\n",
      "predicted label :  7290008836494\n",
      "real label :  7290017812847\n",
      "..........................................\n",
      "image name :  7290017812847 (2).jpeg\n",
      "predicted label :  7290008836494\n",
      "real label :  7290017812847\n",
      "..........................................\n",
      "image name :  7290017812847 (3).jpeg\n",
      "predicted label :  7290008836494\n",
      "real label :  7290017812847\n",
      "..........................................\n",
      "folder name : 7290015350143\n",
      "model name : model3\n",
      "image name :  7290015350143 (1).jpeg\n",
      "predicted label :  7290015350143\n",
      "real label :  7290015350143\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290015350143 (3).jpeg\n",
      "predicted label :  7290015350143\n",
      "real label :  7290015350143\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290015350143 (2).jpeg\n",
      "predicted label :  7290015350143\n",
      "real label :  7290015350143\n",
      "Correctly classified\n",
      "..........................................\n",
      "folder name : 7290008805384\n",
      "model name : model5\n",
      "image name :  7290008805384 (6).jpeg\n",
      "predicted label :  7290000024530\n",
      "real label :  7290008805384\n",
      "..........................................\n",
      "image name :  7290008805384 (4).jpeg\n",
      "predicted label :  7290000024530\n",
      "real label :  7290008805384\n",
      "..........................................\n",
      "image name :  7290008805384 (1).jpeg\n",
      "predicted label :  7290000024530\n",
      "real label :  7290008805384\n",
      "..........................................\n",
      "image name :  7290008805384 (5).jpeg\n",
      "predicted label :  7290000024530\n",
      "real label :  7290008805384\n",
      "..........................................\n",
      "image name :  7290008805384 (3).jpeg\n",
      "predicted label :  7290000024530\n",
      "real label :  7290008805384\n",
      "..........................................\n",
      "image name :  7290008805384 (2).jpeg\n",
      "predicted label :  7290015781121\n",
      "real label :  7290008805384\n",
      "..........................................\n",
      "folder name : 7290017589923\n",
      "model name : model4\n",
      "image name :  7290017589923 (2).jpeg\n",
      "predicted label :  7290017589923\n",
      "real label :  7290017589923\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290017589923 (3).jpeg\n",
      "predicted label :  7290017589923\n",
      "real label :  7290017589923\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290017589923 (1).jpeg\n",
      "predicted label :  7290017589923\n",
      "real label :  7290017589923\n",
      "Correctly classified\n",
      "..........................................\n",
      "folder name : 7290017289601\n",
      "model name : model8\n",
      "image name :  7290017289601.jpeg\n",
      "predicted label :  7290004494049\n",
      "real label :  7290017289601\n",
      "..........................................\n",
      "folder name : 7290015781145\n",
      "model name : model8\n",
      "image name :  7290015781145.jpeg\n",
      "predicted label :  7290000024264\n",
      "real label :  7290015781145\n",
      "..........................................\n",
      "folder name : 7290006256089\n",
      "model name : model12\n",
      "image name :  7290006256089 (3).jpeg\n",
      "predicted label :  7290006256089\n",
      "real label :  7290006256089\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290006256089 (4).jpeg\n",
      "predicted label :  7290006256089\n",
      "real label :  7290006256089\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290006256089 (1).jpeg\n",
      "predicted label :  7290006256089\n",
      "real label :  7290006256089\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290006256089 (5).jpeg\n",
      "predicted label :  7290006256089\n",
      "real label :  7290006256089\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290006256089 (2).jpeg\n",
      "predicted label :  7290006256089\n",
      "real label :  7290006256089\n",
      "Correctly classified\n",
      "..........................................\n",
      "folder name : 7290017647708\n",
      "model name : model7\n",
      "image name :  7290017647708 (2).jpeg\n",
      "predicted label :  7290008836494\n",
      "real label :  7290017647708\n",
      "..........................................\n",
      "image name :  7290017647708 (1).jpeg\n",
      "predicted label :  7290008836494\n",
      "real label :  7290017647708\n",
      "..........................................\n",
      "folder name : 7290108620054\n",
      "model name : model10\n",
      "image name :  7290108620054 (2).jpeg\n",
      "predicted label :  7290004494377\n",
      "real label :  7290108620054\n",
      "..........................................\n",
      "image name :  7290108620054 (1).jpeg\n",
      "predicted label :  7290014503137\n",
      "real label :  7290108620054\n",
      "..........................................\n",
      "folder name : 7290108620115\n",
      "model name : model4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image name :  7290108620115 (3).jpeg\n",
      "predicted label :  7290015781114\n",
      "real label :  7290108620115\n",
      "..........................................\n",
      "image name :  7290108620115 (2).jpeg\n",
      "predicted label :  7290017589923\n",
      "real label :  7290108620115\n",
      "..........................................\n",
      "image name :  7290108620115 (1).jpeg\n",
      "predicted label :  7290015781114\n",
      "real label :  7290108620115\n",
      "..........................................\n",
      "folder name : 7290015781121\n",
      "model name : model5\n",
      "image name :  7290015781121 (1).jpeg\n",
      "predicted label :  7290015781121\n",
      "real label :  7290015781121\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290015781121 (2).jpeg\n",
      "predicted label :  7290015781121\n",
      "real label :  7290015781121\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290015781121 (3).jpeg\n",
      "predicted label :  7290015781121\n",
      "real label :  7290015781121\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290015781121 (4).jpeg\n",
      "predicted label :  7290015781121\n",
      "real label :  7290015781121\n",
      "Correctly classified\n",
      "..........................................\n",
      "folder name : 7290014466609\n",
      "model name : model11\n",
      "image name :  7290014466609.jpeg\n",
      "predicted label :  7290014466609\n",
      "real label :  7290014466609\n",
      "Correctly classified\n",
      "..........................................\n",
      "folder name : 4022025261002\n",
      "model name : model11\n",
      "image name :  4022025261002 (5).jpeg\n",
      "predicted label :  7804414000860\n",
      "real label :  4022025261002\n",
      "..........................................\n",
      "image name :  4022025261002 (3).jpeg\n",
      "predicted label :  7804414000860\n",
      "real label :  4022025261002\n",
      "..........................................\n",
      "image name :  4022025261002 (2).jpeg\n",
      "predicted label :  7804414000860\n",
      "real label :  4022025261002\n",
      "..........................................\n",
      "image name :  4022025261002 (7).jpeg\n",
      "predicted label :  7804414000860\n",
      "real label :  4022025261002\n",
      "..........................................\n",
      "image name :  4022025261002 (6).jpeg\n",
      "predicted label :  7804414000860\n",
      "real label :  4022025261002\n",
      "..........................................\n",
      "image name :  4022025261002 (1).jpeg\n",
      "predicted label :  7804414000860\n",
      "real label :  4022025261002\n",
      "..........................................\n",
      "image name :  4022025261002 (4).jpeg\n",
      "predicted label :  7804414000860\n",
      "real label :  4022025261002\n",
      "..........................................\n",
      "folder name : 7290000521022\n",
      "model name : model6\n",
      "image name :  7290000521022 (4).jpeg\n",
      "predicted label :  7290000521022\n",
      "real label :  7290000521022\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290000521022 (5).jpeg\n",
      "predicted label :  7290000521022\n",
      "real label :  7290000521022\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290000521022 (2).jpeg\n",
      "predicted label :  7290000521022\n",
      "real label :  7290000521022\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290000521022 (3).jpeg\n",
      "predicted label :  7290000521022\n",
      "real label :  7290000521022\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290000521022 (1).jpeg\n",
      "predicted label :  7290000521022\n",
      "real label :  7290000521022\n",
      "Correctly classified\n",
      "..........................................\n",
      "folder name : 7290000023816\n",
      "model name : model1\n",
      "image name :  7290000023816 (4).jpeg\n",
      "predicted label :  7290000023816\n",
      "real label :  7290000023816\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290000023816 (3).jpeg\n",
      "predicted label :  7290000023816\n",
      "real label :  7290000023816\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290000023816 (2).jpeg\n",
      "predicted label :  7290000023816\n",
      "real label :  7290000023816\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290000023816 (1).jpeg\n",
      "predicted label :  7290000023816\n",
      "real label :  7290000023816\n",
      "Correctly classified\n",
      "..........................................\n",
      "folder name : 4022025001929\n",
      "model name : model10\n",
      "image name :  4022025001929.jpeg\n",
      "predicted label :  7290004494377\n",
      "real label :  4022025001929\n",
      "..........................................\n",
      "folder name : 7290017812830\n",
      "model name : model7\n",
      "image name :  7290017812830 (1).jpeg\n",
      "predicted label :  7290008836494\n",
      "real label :  7290017812830\n",
      "..........................................\n",
      "image name :  7290017812830 (2).jpeg\n",
      "predicted label :  7290008836494\n",
      "real label :  7290017812830\n",
      "..........................................\n",
      "folder name : 7290008803090\n",
      "model name : model12\n",
      "image name :  7290008803090 (2).jpeg\n",
      "predicted label :  7290006256089\n",
      "real label :  7290008803090\n",
      "..........................................\n",
      "image name :  7290008803090 (1).jpeg\n",
      "predicted label :  7290006256089\n",
      "real label :  7290008803090\n",
      "..........................................\n",
      "image name :  7290008803090 (9).jpeg\n",
      "predicted label :  7290006256089\n",
      "real label :  7290008803090\n",
      "..........................................\n",
      "image name :  7290008803090 (8).jpeg\n",
      "predicted label :  7290006256089\n",
      "real label :  7290008803090\n",
      "..........................................\n",
      "image name :  7290008803090 (7).jpeg\n",
      "predicted label :  7290006256089\n",
      "real label :  7290008803090\n",
      "..........................................\n",
      "image name :  7290008803090 (6).jpeg\n",
      "predicted label :  7290006256089\n",
      "real label :  7290008803090\n",
      "..........................................\n",
      "image name :  7290008803090 (5).jpeg\n",
      "predicted label :  7290012576614\n",
      "real label :  7290008803090\n",
      "..........................................\n",
      "image name :  7290008803090 (3).jpeg\n",
      "predicted label :  7290006256089\n",
      "real label :  7290008803090\n",
      "..........................................\n",
      "image name :  7290008803090 (4).jpeg\n",
      "predicted label :  7290006256089\n",
      "real label :  7290008803090\n",
      "..........................................\n",
      "folder name : 7290015781138\n",
      "model name : model9\n",
      "image name :  7290015781138.jpeg\n",
      "predicted label :  7290000024516\n",
      "real label :  7290015781138\n",
      "..........................................\n",
      "folder name : 7290004658946\n",
      "model name : model6\n",
      "image name :  7290004658946 (2).jpeg\n",
      "predicted label :  7290000521022\n",
      "real label :  7290004658946\n",
      "..........................................\n",
      "image name :  7290004658946 (1).jpeg\n",
      "predicted label :  7290000521022\n",
      "real label :  7290004658946\n",
      "..........................................\n",
      "image name :  7290004658946 (3).jpeg\n",
      "predicted label :  7290000521022\n",
      "real label :  7290004658946\n",
      "..........................................\n",
      "folder name : 7290008802512\n",
      "model name : model3\n",
      "image name :  7290008802512 (3).jpeg\n",
      "predicted label :  7290008802512\n",
      "real label :  7290008802512\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290008802512 (2).jpeg\n",
      "predicted label :  7290008802512\n",
      "real label :  7290008802512\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290008802512 (1).jpeg\n",
      "predicted label :  7290008802512\n",
      "real label :  7290008802512\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290008802512 (4).jpeg\n",
      "predicted label :  7290008802512\n",
      "real label :  7290008802512\n",
      "Correctly classified\n",
      "..........................................\n",
      "folder name : 7290015781114\n",
      "model name : model4\n",
      "image name :  7290015781114 (3).jpeg\n",
      "predicted label :  7290015781114\n",
      "real label :  7290015781114\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290015781114 (1).jpeg\n",
      "predicted label :  7290015781114\n",
      "real label :  7290015781114\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290015781114 (4).jpeg\n",
      "predicted label :  7290015781114\n",
      "real label :  7290015781114\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290015781114 (2).jpeg\n",
      "predicted label :  7290015781114\n",
      "real label :  7290015781114\n",
      "Correctly classified\n",
      "..........................................\n",
      "folder name : 7290000023830\n",
      "model name : model4\n",
      "image name :  7290000023830.jpeg\n",
      "predicted label :  7290015781114\n",
      "real label :  7290000023830\n",
      "..........................................\n",
      "folder name : 7290008805964\n",
      "model name : model2\n",
      "image name :  7290008805964 (2).jpeg\n",
      "predicted label :  7290000023847\n",
      "real label :  7290008805964\n",
      "..........................................\n",
      "image name :  7290008805964 (1).jpeg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted label :  7290017289205\n",
      "real label :  7290008805964\n",
      "..........................................\n",
      "folder name : 7290012576607\n",
      "model name : model12\n",
      "image name :  7290012576607 (3).jpeg\n",
      "predicted label :  7290012576607\n",
      "real label :  7290012576607\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290012576607 (1).jpeg\n",
      "predicted label :  7290012576607\n",
      "real label :  7290012576607\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290012576607 (2).jpeg\n",
      "predicted label :  7290012576607\n",
      "real label :  7290012576607\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290012576607 (4).jpeg\n",
      "predicted label :  7290012576607\n",
      "real label :  7290012576607\n",
      "Correctly classified\n",
      "..........................................\n",
      "folder name : 7290015951227\n",
      "model name : model7\n",
      "image name :  7290015951227 (2).jpeg\n",
      "predicted label :  7290008836494\n",
      "real label :  7290015951227\n",
      "..........................................\n",
      "image name :  7290015951227 (3).jpeg\n",
      "predicted label :  7290008836494\n",
      "real label :  7290015951227\n",
      "..........................................\n",
      "image name :  7290015951227 (1).jpeg\n",
      "predicted label :  7290008836494\n",
      "real label :  7290015951227\n",
      "..........................................\n",
      "image name :  7290015951227 (4).jpeg\n",
      "predicted label :  7290008836494\n",
      "real label :  7290015951227\n",
      "..........................................\n",
      "folder name : 7290016717631\n",
      "model name : model12\n",
      "image name :  7290016717631 (2).jpeg\n",
      "predicted label :  7290006256089\n",
      "real label :  7290016717631\n",
      "..........................................\n",
      "image name :  7290016717631 (1).jpeg\n",
      "predicted label :  7290006256089\n",
      "real label :  7290016717631\n",
      "..........................................\n",
      "folder name : 7290018294208\n",
      "model name : model8\n",
      "image name :  7290018294208 (2).jpeg\n",
      "predicted label :  7290000024264\n",
      "real label :  7290018294208\n",
      "..........................................\n",
      "image name :  7290018294208 (1).jpeg\n",
      "predicted label :  7290000024264\n",
      "real label :  7290018294208\n",
      "..........................................\n",
      "folder name : 7290017812069\n",
      "model name : model5\n",
      "image name :  7290017812069 (1).jpeg\n",
      "predicted label :  7290015781121\n",
      "real label :  7290017812069\n",
      "..........................................\n",
      "image name :  7290017812069 (2).jpeg\n",
      "predicted label :  7290015781121\n",
      "real label :  7290017812069\n",
      "..........................................\n",
      "folder name : 7290015781107\n",
      "model name : model10\n",
      "image name :  7290015781107 (2).jpeg\n",
      "predicted label :  7290004494377\n",
      "real label :  7290015781107\n",
      "..........................................\n",
      "image name :  7290015781107 (1).jpeg\n",
      "predicted label :  7290004494377\n",
      "real label :  7290015781107\n",
      "..........................................\n",
      "folder name : 7290015781008\n",
      "model name : model9\n",
      "image name :  7290015781008 (1).jpeg\n",
      "predicted label :  7290015781008\n",
      "real label :  7290015781008\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290015781008 (3).jpeg\n",
      "predicted label :  7290015781008\n",
      "real label :  7290015781008\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290015781008 (2).jpeg\n",
      "predicted label :  7290015781008\n",
      "real label :  7290015781008\n",
      "Correctly classified\n",
      "..........................................\n",
      "folder name : 7290000521428\n",
      "model name : model9\n",
      "image name :  7290000521428 (2).jpeg\n",
      "predicted label :  7290000024516\n",
      "real label :  7290000521428\n",
      "..........................................\n",
      "image name :  7290000521428 (1).jpeg\n",
      "predicted label :  7290000024516\n",
      "real label :  7290000521428\n",
      "..........................................\n",
      "folder name : 7290006256775\n",
      "model name : model1\n",
      "image name :  7290006256775 (1).jpeg\n",
      "predicted label :  7290006256775\n",
      "real label :  7290006256775\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290006256775 (2).jpeg\n",
      "predicted label :  7290006256775\n",
      "real label :  7290006256775\n",
      "Correctly classified\n",
      "..........................................\n",
      "folder name : 7290108620078\n",
      "model name : model1\n",
      "image name :  7290108620078.jpeg\n",
      "predicted label :  7290006256775\n",
      "real label :  7290108620078\n",
      "..........................................\n",
      "folder name : 7290008801850\n",
      "model name : model4\n",
      "image name :  7290008801850 (5).jpeg\n",
      "predicted label :  7290008801850\n",
      "real label :  7290008801850\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290008801850 (4).jpeg\n",
      "predicted label :  7290008801850\n",
      "real label :  7290008801850\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290008801850 (3).jpeg\n",
      "predicted label :  7290103681210\n",
      "real label :  7290008801850\n",
      "..........................................\n",
      "image name :  7290008801850 (1).jpeg\n",
      "predicted label :  7290103681210\n",
      "real label :  7290008801850\n",
      "..........................................\n",
      "image name :  7290008801850 (6).jpeg\n",
      "predicted label :  7290103681210\n",
      "real label :  7290008801850\n",
      "..........................................\n",
      "image name :  7290008801850 (2).jpeg\n",
      "predicted label :  7290008801850\n",
      "real label :  7290008801850\n",
      "Correctly classified\n",
      "..........................................\n",
      "folder name : 7290017289120\n",
      "model name : model4\n",
      "image name :  7290017289120 (1).jpeg\n",
      "predicted label :  7290017289120\n",
      "real label :  7290017289120\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290017289120 (2).jpeg\n",
      "predicted label :  7290015781114\n",
      "real label :  7290017289120\n",
      "..........................................\n",
      "folder name : 7290017289182\n",
      "model name : model1\n",
      "image name :  7290017289182 (1).jpeg\n",
      "predicted label :  7290017289182\n",
      "real label :  7290017289182\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290017289182 (2).jpeg\n",
      "predicted label :  7290017289182\n",
      "real label :  7290017289182\n",
      "Correctly classified\n",
      "..........................................\n",
      "folder name : 7290017812861\n",
      "model name : model1\n",
      "image name :  7290017812861.jpeg\n",
      "predicted label :  7290014503144\n",
      "real label :  7290017812861\n",
      "..........................................\n",
      "folder name : 7290008801843\n",
      "model name : model5\n",
      "image name :  7290008801843 (6).jpeg\n",
      "predicted label :  7290015781121\n",
      "real label :  7290008801843\n",
      "..........................................\n",
      "image name :  7290008801843 (7).jpeg\n",
      "predicted label :  7290015781121\n",
      "real label :  7290008801843\n",
      "..........................................\n",
      "image name :  7290008801843 (2).jpeg\n",
      "predicted label :  7290000024530\n",
      "real label :  7290008801843\n",
      "..........................................\n",
      "image name :  7290008801843 (3).jpeg\n",
      "predicted label :  7290000024530\n",
      "real label :  7290008801843\n",
      "..........................................\n",
      "image name :  7290008801843 (4).jpeg\n",
      "predicted label :  7290015781121\n",
      "real label :  7290008801843\n",
      "..........................................\n",
      "image name :  7290008801843 (1).jpeg\n",
      "predicted label :  7290015781121\n",
      "real label :  7290008801843\n",
      "..........................................\n",
      "image name :  7290008801843 (5).jpeg\n",
      "predicted label :  7290015781121\n",
      "real label :  7290008801843\n",
      "..........................................\n",
      "folder name : 7290000023809\n",
      "model name : model5\n",
      "image name :  7290000023809 (2).jpeg\n",
      "predicted label :  7290015781121\n",
      "real label :  7290000023809\n",
      "..........................................\n",
      "image name :  7290000023809 (3).jpeg\n",
      "predicted label :  7290015781121\n",
      "real label :  7290000023809\n",
      "..........................................\n",
      "image name :  7290000023809 (4).jpeg\n",
      "predicted label :  7290015781121\n",
      "real label :  7290000023809\n",
      "..........................................\n",
      "image name :  7290000023809 (1).jpeg\n",
      "predicted label :  7290015781121\n",
      "real label :  7290000023809\n",
      "..........................................\n",
      "folder name : 7290108620092\n",
      "model name : model12\n",
      "image name :  7290108620092 (1).jpeg\n",
      "predicted label :  7290006256089\n",
      "real label :  7290108620092\n",
      "..........................................\n",
      "image name :  7290108620092 (4).jpeg\n",
      "predicted label :  7290006256089\n",
      "real label :  7290108620092\n",
      "..........................................\n",
      "image name :  7290108620092 (3).jpeg\n",
      "predicted label :  7290006256089\n",
      "real label :  7290108620092\n",
      "..........................................\n",
      "image name :  7290108620092 (2).jpeg\n",
      "predicted label :  7290006256089\n",
      "real label :  7290108620092\n",
      "..........................................\n",
      "folder name : 7290016717099\n",
      "model name : model3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image name :  7290016717099 (1).jpeg\n",
      "predicted label :  7290008670159\n",
      "real label :  7290016717099\n",
      "..........................................\n",
      "image name :  7290016717099 (3).jpeg\n",
      "predicted label :  7290008670159\n",
      "real label :  7290016717099\n",
      "..........................................\n",
      "image name :  7290016717099 (5).jpeg\n",
      "predicted label :  7290008670159\n",
      "real label :  7290016717099\n",
      "..........................................\n",
      "image name :  7290016717099 (2).jpeg\n",
      "predicted label :  7290008670159\n",
      "real label :  7290016717099\n",
      "..........................................\n",
      "image name :  7290016717099 (4).jpeg\n",
      "predicted label :  7290008670159\n",
      "real label :  7290016717099\n",
      "..........................................\n",
      "folder name : 7290017647722\n",
      "model name : model4\n",
      "image name :  7290017647722 (2).jpeg\n",
      "predicted label :  7290103681210\n",
      "real label :  7290017647722\n",
      "..........................................\n",
      "image name :  7290017647722 (1).jpeg\n",
      "predicted label :  7290103681210\n",
      "real label :  7290017647722\n",
      "..........................................\n",
      "folder name : 7290015781091\n",
      "model name : model11\n",
      "image name :  7290015781091 (2).jpeg\n",
      "predicted label :  7290015781091\n",
      "real label :  7290015781091\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290015781091 (1).jpeg\n",
      "predicted label :  7290015781091\n",
      "real label :  7290015781091\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290015781091 (3).jpeg\n",
      "predicted label :  7290015781091\n",
      "real label :  7290015781091\n",
      "Correctly classified\n",
      "..........................................\n",
      "folder name : 7290014466463\n",
      "model name : model10\n",
      "image name :  7290014466463 (1).jpeg\n",
      "predicted label :  7290004494377\n",
      "real label :  7290014466463\n",
      "..........................................\n",
      "image name :  7290014466463 (3).jpeg\n",
      "predicted label :  7290004494377\n",
      "real label :  7290014466463\n",
      "..........................................\n",
      "image name :  7290014466463 (2).jpeg\n",
      "predicted label :  7290004494377\n",
      "real label :  7290014466463\n",
      "..........................................\n",
      "folder name : 7290015350150\n",
      "model name : model6\n",
      "image name :  7290015350150 (7).jpeg\n",
      "predicted label :  7290000521022\n",
      "real label :  7290015350150\n",
      "..........................................\n",
      "image name :  7290015350150 (3).jpeg\n",
      "predicted label :  7290000521022\n",
      "real label :  7290015350150\n",
      "..........................................\n",
      "image name :  7290015350150 (2).jpeg\n",
      "predicted label :  7290000521022\n",
      "real label :  7290015350150\n",
      "..........................................\n",
      "image name :  7290015350150 (9).jpeg\n",
      "predicted label :  7290000521022\n",
      "real label :  7290015350150\n",
      "..........................................\n",
      "image name :  7290015350150 (4).jpeg\n",
      "predicted label :  7290000521022\n",
      "real label :  7290015350150\n",
      "..........................................\n",
      "image name :  7290015350150 (1).jpeg\n",
      "predicted label :  7290000521022\n",
      "real label :  7290015350150\n",
      "..........................................\n",
      "image name :  7290015350150 (6).jpeg\n",
      "predicted label :  7290000521022\n",
      "real label :  7290015350150\n",
      "..........................................\n",
      "image name :  7290015350150 (5).jpeg\n",
      "predicted label :  7290000521022\n",
      "real label :  7290015350150\n",
      "..........................................\n",
      "image name :  7290015350150 (8).jpeg\n",
      "predicted label :  7290000521022\n",
      "real label :  7290015350150\n",
      "..........................................\n",
      "folder name : 7290000023847\n",
      "model name : model2\n",
      "image name :  7290000023847 (2).jpeg\n",
      "predicted label :  7290000023847\n",
      "real label :  7290000023847\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290000023847 (3).jpeg\n",
      "predicted label :  7290000023847\n",
      "real label :  7290000023847\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290000023847 (1).jpeg\n",
      "predicted label :  7290000023847\n",
      "real label :  7290000023847\n",
      "Correctly classified\n",
      "..........................................\n",
      "folder name : 8422443005213\n",
      "model name : model9\n",
      "image name :  8422443005213 (1).jpeg\n",
      "predicted label :  7290000024516\n",
      "real label :  8422443005213\n",
      "..........................................\n",
      "image name :  8422443005213 (3).jpeg\n",
      "predicted label :  7290000024516\n",
      "real label :  8422443005213\n",
      "..........................................\n",
      "image name :  8422443005213 (2).jpeg\n",
      "predicted label :  7290000024516\n",
      "real label :  8422443005213\n",
      "..........................................\n",
      "image name :  8422443005213 (4).jpeg\n",
      "predicted label :  7290000024516\n",
      "real label :  8422443005213\n",
      "..........................................\n",
      "folder name : 7290008804745\n",
      "model name : model3\n",
      "image name :  7290008804745.jpeg\n",
      "predicted label :  7290103681180\n",
      "real label :  7290008804745\n",
      "..........................................\n",
      "folder name : 7290015781299\n",
      "model name : model9\n",
      "image name :  7290015781299 (1).jpeg\n",
      "predicted label :  7290015781299\n",
      "real label :  7290015781299\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290015781299 (4).jpeg\n",
      "predicted label :  7290015781299\n",
      "real label :  7290015781299\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290015781299 (3).jpeg\n",
      "predicted label :  7290015781299\n",
      "real label :  7290015781299\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  7290015781299 (2).jpeg\n",
      "predicted label :  7290015781008\n",
      "real label :  7290015781299\n",
      "..........................................\n",
      "folder name : 7290008804455\n",
      "model name : model7\n",
      "image name :  7290008804455 (1).jpeg\n",
      "predicted label :  7290008836494\n",
      "real label :  7290008804455\n",
      "..........................................\n",
      "image name :  7290008804455 (2).jpeg\n",
      "predicted label :  7290008836494\n",
      "real label :  7290008804455\n",
      "..........................................\n",
      "folder name : 4022025002100\n",
      "model name : model4\n",
      "image name :  4022025002100 (1).jpeg\n",
      "predicted label :  4022025002100\n",
      "real label :  4022025002100\n",
      "Correctly classified\n",
      "..........................................\n",
      "image name :  4022025002100 (2).jpeg\n",
      "predicted label :  4022025002100\n",
      "real label :  4022025002100\n",
      "Correctly classified\n",
      "..........................................\n",
      "folder name : 7798141877836\n",
      "model name : model4\n",
      "image name :  7798141877836 (2).jpeg\n",
      "predicted label :  7290103681210\n",
      "real label :  7798141877836\n",
      "..........................................\n",
      "image name :  7798141877836 (1).jpeg\n",
      "predicted label :  7290017589923\n",
      "real label :  7798141877836\n",
      "..........................................\n",
      "Number of images :  243\n",
      "Number of correctly classified images :  78\n",
      "Accuray :  0.32098765432098764\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "correct = 0\n",
    "for folder in folder_names:\n",
    "    print('folder name :',folder)\n",
    "    for column in df.columns:\n",
    "        if folder  in df[column].unique():\n",
    "            model  = column\n",
    "    print('model name :',model)\n",
    "    \n",
    "    section_number = model[5:]\n",
    "    \n",
    "    data_dir = Path(\"/home/orelit/Projects -Sathsara/Planigo/data/WINE_SECTIONS_NEW/section{}\".\n",
    "                    format(section_number))\n",
    "    ds=ImageFolder(data_dir)\n",
    "    \n",
    "    label2id = {}\n",
    "    id2label = {}\n",
    "    for i, class_name in enumerate(ds.classes):\n",
    "        label2id[class_name] = str(i)\n",
    "        id2label[str(i)] = class_name\n",
    "        \n",
    "    model_path = '/home/orelit/Projects -Sathsara/Planigo/Models/VIT_WINE/{}'.format(model)\n",
    "    wine_model = ViTForImageClassification.from_pretrained(\n",
    "         model_path,\n",
    "         num_labels=len(label2id),\n",
    "         label2id=label2id,\n",
    "         id2label=id2label)\n",
    "    for image in os.listdir(test_data_path+'/'+folder):\n",
    "        print('image name : ',image)\n",
    "        img = test_data_path+'/'+folder +'/'+image\n",
    "        pred= prediction(img,wine_model)\n",
    "        print(\"predicted label : \",pred)\n",
    "        test_label = image[image.rfind('/')+1:]\n",
    "        real_class = test_label[0:13]\n",
    "        print('real label : ',real_class)\n",
    "        if real_class == pred:\n",
    "            correct = correct +1\n",
    "            print(\"Correctly classified\")\n",
    "        count = count + 1\n",
    "        print('..........................................')\n",
    "\n",
    "acc = correct/count\n",
    "print(\"Number of images : \",count)\n",
    "print(\"Number of correctly classified images : \",correct)\n",
    "print(\"Accuray : \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5de678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d01e38b9",
   "metadata": {},
   "source": [
    "# VIT low variance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d33a2ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d8212c3b2043a4a7b7e84f8026d1c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/18122 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca356ab6d7704bc7bb552203fb579f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/4523 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-41910383854bf899\n",
      "Reusing dataset imagefolder (/home/orelit/.cache/huggingface/datasets/imagefolder/default-41910383854bf899/0.0.0/0fc50c79b681877cc46b23245a6ef5333d036f48db40d53765a68034bc48faff)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09fc0e8f847403589ae650aefa5654f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"imagefolder\", \n",
    "    data_dir=\"/home/orelit/Projects -Sathsara/Planigo/data/VIT_train_wine_low_variance_test_augmented_splitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c01a313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'validation'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63c5a700",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataset['train'].features['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04adf736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72d8ad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTFeatureExtractor\n",
    "\n",
    "\n",
    "checkpoint = 'google/vit-base-patch16-224-in21k'\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53ce5d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import (\n",
    "    Compose,\n",
    "    Normalize,\n",
    "    Resize,\n",
    "    RandomResizedCrop,\n",
    "    RandomHorizontalFlip,\n",
    "    RandomAdjustSharpness,\n",
    "    ToTensor,\n",
    "    ToPILImage\n",
    ")\n",
    "\n",
    "\n",
    "# train\n",
    "train_aug_transforms = Compose([\n",
    "    RandomResizedCrop(size=feature_extractor.size),\n",
    "    RandomHorizontalFlip(p=0.5),\n",
    "    RandomAdjustSharpness(sharpness_factor=5, p=0.5),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std),\n",
    "])\n",
    "\n",
    "\n",
    "# validation/test\n",
    "valid_aug_transforms = Compose([\n",
    "    Resize(size=(feature_extractor.size, feature_extractor.size)),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9235454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_train_aug_transforms(examples):\n",
    "  examples['pixel_values'] = [train_aug_transforms(img.convert('RGB')) for img in examples['image']]\n",
    "  return examples\n",
    "\n",
    "\n",
    "def apply_valid_aug_transforms(examples):\n",
    "  examples['pixel_values'] = [valid_aug_transforms(img.convert('RGB')) for img in examples['image']]\n",
    "  return examples\n",
    "\n",
    "\n",
    "dataset['train'].set_transform(apply_train_aug_transforms)\n",
    "dataset['validation'].set_transform(apply_valid_aug_transforms)\n",
    "\n",
    "datasets_processed = dataset.rename_column('label', 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58c9231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTForImageClassification\n",
    "\n",
    "\n",
    "def model_init():\n",
    "    vit_model = ViTForImageClassification.from_pretrained(\n",
    "        checkpoint,\n",
    "        num_labels=labels.num_classes,\n",
    "        id2label={index: label for index, label in enumerate(labels.names)},\n",
    "        label2id={label: index for index, label in enumerate(labels.names)}\n",
    "    )\n",
    "    return vit_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea27db9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics_fn(eval_preds):\n",
    "  metrics = dict()\n",
    "  \n",
    "  accuracy_metric = load_metric('accuracy')\n",
    "  precision_metric = load_metric('precision')\n",
    "  recall_metric = load_metric('recall')\n",
    "  f1_metric = load_metric('f1')\n",
    "\n",
    "\n",
    "  logits = eval_preds.predictions\n",
    "  labels = eval_preds.label_ids\n",
    "  preds = np.argmax(logits, axis=-1)  \n",
    "  \n",
    "  metrics.update(accuracy_metric.compute(predictions=preds, references=labels))\n",
    "  metrics.update(precision_metric.compute(predictions=preds, references=labels, average='weighted'))\n",
    "  metrics.update(recall_metric.compute(predictions=preds, references=labels, average='weighted'))\n",
    "  metrics.update(f1_metric.compute(predictions=preds, references=labels, average='weighted'))\n",
    "\n",
    "\n",
    "  return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fd78fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def collate_fn(examples):\n",
    "  pixel_values = torch.stack([example['pixel_values'] for example in examples])\n",
    "  labels = torch.tensor([example['labels'] for example in examples])\n",
    "  return {'pixel_values': pixel_values, 'labels': labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0650aab5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "loading configuration file config.json from cache at /home/orelit/.cache/huggingface/hub/models--google--vit-base-patch16-224-in21k/snapshots/1ba429d32753f33a0660b80ac6f43a3c80c18938/config.json\n",
      "Model config ViTConfig {\n",
      "  \"_name_or_path\": \"google/vit-base-patch16-224-in21k\",\n",
      "  \"architectures\": [\n",
      "    \"ViTModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"7290000023809\",\n",
      "    \"1\": \"7290000023847\",\n",
      "    \"2\": \"7290000024264\",\n",
      "    \"3\": \"7290006256089\",\n",
      "    \"4\": \"7290008670142\",\n",
      "    \"5\": \"7290008670159\",\n",
      "    \"6\": \"7290008801843\",\n",
      "    \"7\": \"7290008802512\",\n",
      "    \"8\": \"7290008804189\",\n",
      "    \"9\": \"7290012576607\",\n",
      "    \"10\": \"7290014466609\",\n",
      "    \"11\": \"7290015350150\",\n",
      "    \"12\": \"7290015781008\",\n",
      "    \"13\": \"7290015781015\",\n",
      "    \"14\": \"7290015781114\",\n",
      "    \"15\": \"7290015951227\"\n",
      "  },\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"7290000023809\": 0,\n",
      "    \"7290000023847\": 1,\n",
      "    \"7290000024264\": 2,\n",
      "    \"7290006256089\": 3,\n",
      "    \"7290008670142\": 4,\n",
      "    \"7290008670159\": 5,\n",
      "    \"7290008801843\": 6,\n",
      "    \"7290008802512\": 7,\n",
      "    \"7290008804189\": 8,\n",
      "    \"7290012576607\": 9,\n",
      "    \"7290014466609\": 10,\n",
      "    \"7290015350150\": 11,\n",
      "    \"7290015781008\": 12,\n",
      "    \"7290015781015\": 13,\n",
      "    \"7290015781114\": 14,\n",
      "    \"7290015951227\": 15\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": true,\n",
      "  \"transformers_version\": \"4.22.1\"\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/orelit/.cache/huggingface/hub/models--google--vit-base-patch16-224-in21k/snapshots/1ba429d32753f33a0660b80ac6f43a3c80c18938/pytorch_model.bin\n",
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using cuda_amp half precision backend\n",
      "loading configuration file config.json from cache at /home/orelit/.cache/huggingface/hub/models--google--vit-base-patch16-224-in21k/snapshots/1ba429d32753f33a0660b80ac6f43a3c80c18938/config.json\n",
      "Model config ViTConfig {\n",
      "  \"_name_or_path\": \"google/vit-base-patch16-224-in21k\",\n",
      "  \"architectures\": [\n",
      "    \"ViTModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"7290000023809\",\n",
      "    \"1\": \"7290000023847\",\n",
      "    \"2\": \"7290000024264\",\n",
      "    \"3\": \"7290006256089\",\n",
      "    \"4\": \"7290008670142\",\n",
      "    \"5\": \"7290008670159\",\n",
      "    \"6\": \"7290008801843\",\n",
      "    \"7\": \"7290008802512\",\n",
      "    \"8\": \"7290008804189\",\n",
      "    \"9\": \"7290012576607\",\n",
      "    \"10\": \"7290014466609\",\n",
      "    \"11\": \"7290015350150\",\n",
      "    \"12\": \"7290015781008\",\n",
      "    \"13\": \"7290015781015\",\n",
      "    \"14\": \"7290015781114\",\n",
      "    \"15\": \"7290015951227\"\n",
      "  },\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"7290000023809\": 0,\n",
      "    \"7290000023847\": 1,\n",
      "    \"7290000024264\": 2,\n",
      "    \"7290006256089\": 3,\n",
      "    \"7290008670142\": 4,\n",
      "    \"7290008670159\": 5,\n",
      "    \"7290008801843\": 6,\n",
      "    \"7290008802512\": 7,\n",
      "    \"7290008804189\": 8,\n",
      "    \"7290012576607\": 9,\n",
      "    \"7290014466609\": 10,\n",
      "    \"7290015350150\": 11,\n",
      "    \"7290015781008\": 12,\n",
      "    \"7290015781015\": 13,\n",
      "    \"7290015781114\": 14,\n",
      "    \"7290015951227\": 15\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": true,\n",
      "  \"transformers_version\": \"4.22.1\"\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/orelit/.cache/huggingface/hub/models--google--vit-base-patch16-224-in21k/snapshots/1ba429d32753f33a0660b80ac6f43a3c80c18938/pytorch_model.bin\n",
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/orelit/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 18122\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2835\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msathsara_rasantha\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2af7e9a196494b6d8f87a5f47dd8742f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.033336941401163736, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/orelit/Projects -Sathsara/Planigo/wandb/run-20220928_111503-pw1y2s62</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sathsara_rasantha/huggingface/runs/pw1y2s62\" target=\"_blank\">/home/orelit/Projects -Sathsara/Planigo/Models/wine_low_variance_augmented_data_logs</a></strong> to <a href=\"https://wandb.ai/sathsara_rasantha/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2835' max='2835' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2835/2835 32:47, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.606700</td>\n",
       "      <td>0.643301</td>\n",
       "      <td>0.977228</td>\n",
       "      <td>0.980610</td>\n",
       "      <td>0.977228</td>\n",
       "      <td>0.976048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.284437</td>\n",
       "      <td>0.991156</td>\n",
       "      <td>0.991624</td>\n",
       "      <td>0.991156</td>\n",
       "      <td>0.990883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.272800</td>\n",
       "      <td>0.182262</td>\n",
       "      <td>0.989609</td>\n",
       "      <td>0.990632</td>\n",
       "      <td>0.989609</td>\n",
       "      <td>0.989269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>0.155605</td>\n",
       "      <td>0.989609</td>\n",
       "      <td>0.990633</td>\n",
       "      <td>0.989609</td>\n",
       "      <td>0.989210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.140400</td>\n",
       "      <td>0.131496</td>\n",
       "      <td>0.990051</td>\n",
       "      <td>0.990992</td>\n",
       "      <td>0.990051</td>\n",
       "      <td>0.989690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 4523\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/orelit/Projects -Sathsara/Planigo/Models/wine_low_variance_augmented_data_logs/checkpoint-567\n",
      "Configuration saved in /home/orelit/Projects -Sathsara/Planigo/Models/wine_low_variance_augmented_data_logs/checkpoint-567/config.json\n",
      "Model weights saved in /home/orelit/Projects -Sathsara/Planigo/Models/wine_low_variance_augmented_data_logs/checkpoint-567/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4523\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/orelit/Projects -Sathsara/Planigo/Models/wine_low_variance_augmented_data_logs/checkpoint-1134\n",
      "Configuration saved in /home/orelit/Projects -Sathsara/Planigo/Models/wine_low_variance_augmented_data_logs/checkpoint-1134/config.json\n",
      "Model weights saved in /home/orelit/Projects -Sathsara/Planigo/Models/wine_low_variance_augmented_data_logs/checkpoint-1134/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4523\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/orelit/Projects -Sathsara/Planigo/Models/wine_low_variance_augmented_data_logs/checkpoint-1701\n",
      "Configuration saved in /home/orelit/Projects -Sathsara/Planigo/Models/wine_low_variance_augmented_data_logs/checkpoint-1701/config.json\n",
      "Model weights saved in /home/orelit/Projects -Sathsara/Planigo/Models/wine_low_variance_augmented_data_logs/checkpoint-1701/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4523\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/orelit/Projects -Sathsara/Planigo/Models/wine_low_variance_augmented_data_logs/checkpoint-2268\n",
      "Configuration saved in /home/orelit/Projects -Sathsara/Planigo/Models/wine_low_variance_augmented_data_logs/checkpoint-2268/config.json\n",
      "Model weights saved in /home/orelit/Projects -Sathsara/Planigo/Models/wine_low_variance_augmented_data_logs/checkpoint-2268/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4523\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/orelit/Projects -Sathsara/Planigo/Models/wine_low_variance_augmented_data_logs/checkpoint-2835\n",
      "Configuration saved in /home/orelit/Projects -Sathsara/Planigo/Models/wine_low_variance_augmented_data_logs/checkpoint-2835/config.json\n",
      "Model weights saved in /home/orelit/Projects -Sathsara/Planigo/Models/wine_low_variance_augmented_data_logs/checkpoint-2835/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/orelit/Projects -Sathsara/Planigo/Models/wine_low_variance_augmented_data_logs/checkpoint-2835 (score: 0.13149595260620117).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2835, training_loss=0.4959030272468688, metrics={'train_runtime': 1978.8196, 'train_samples_per_second': 45.79, 'train_steps_per_second': 1.433, 'total_flos': 7.022430225919181e+18, 'train_loss': 0.4959030272468688, 'epoch': 5.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "pl.seed_everything(42)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "        output_dir='/home/orelit/Projects -Sathsara/Planigo/Models/wine_low_variance_augmented_data_logs',\n",
    "        num_train_epochs=5,\n",
    "        learning_rate=2e-5,\n",
    "        weight_decay= 0.00025,\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=32,\n",
    "        save_strategy='epoch',\n",
    "        evaluation_strategy='epoch',\n",
    "        load_best_model_at_end=True,\n",
    "        remove_unused_columns=False,\n",
    "        fp16=True\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "        # model,\n",
    "        model_init=model_init,\n",
    "        args=training_args,\n",
    "        data_collator=collate_fn,\n",
    "        train_dataset=datasets_processed['train'],\n",
    "        eval_dataset=datasets_processed['validation'],\n",
    "        compute_metrics=compute_metrics_fn,\n",
    "    )\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "af6b680e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_checkpoint = '/home/orelit/Projects -Sathsara/Planigo/Models/wine_low_variance_augmented_data_logs/checkpoint-2835'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d897b913",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/orelit/Projects -Sathsara/Planigo/Models/wine_low_variance_augmented_data_logs/checkpoint-2835/config.json\n",
      "Model config ViTConfig {\n",
      "  \"_name_or_path\": \"google/vit-base-patch16-224-in21k\",\n",
      "  \"architectures\": [\n",
      "    \"ViTForImageClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"7290000023809\",\n",
      "    \"1\": \"7290000023847\",\n",
      "    \"2\": \"7290000024264\",\n",
      "    \"3\": \"7290006256089\",\n",
      "    \"4\": \"7290008670142\",\n",
      "    \"5\": \"7290008670159\",\n",
      "    \"6\": \"7290008801843\",\n",
      "    \"7\": \"7290008802512\",\n",
      "    \"8\": \"7290008804189\",\n",
      "    \"9\": \"7290012576607\",\n",
      "    \"10\": \"7290014466609\",\n",
      "    \"11\": \"7290015350150\",\n",
      "    \"12\": \"7290015781008\",\n",
      "    \"13\": \"7290015781015\",\n",
      "    \"14\": \"7290015781114\",\n",
      "    \"15\": \"7290015951227\"\n",
      "  },\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"7290000023809\": 0,\n",
      "    \"7290000023847\": 1,\n",
      "    \"7290000024264\": 2,\n",
      "    \"7290006256089\": 3,\n",
      "    \"7290008670142\": 4,\n",
      "    \"7290008670159\": 5,\n",
      "    \"7290008801843\": 6,\n",
      "    \"7290008802512\": 7,\n",
      "    \"7290008804189\": 8,\n",
      "    \"7290012576607\": 9,\n",
      "    \"7290014466609\": 10,\n",
      "    \"7290015350150\": 11,\n",
      "    \"7290015781008\": 12,\n",
      "    \"7290015781015\": 13,\n",
      "    \"7290015781114\": 14,\n",
      "    \"7290015951227\": 15\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qkv_bias\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.22.1\"\n",
      "}\n",
      "\n",
      "loading weights file /home/orelit/Projects -Sathsara/Planigo/Models/wine_low_variance_augmented_data_logs/checkpoint-2835/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing ViTForImageClassification.\n",
      "\n",
      "All the weights of ViTForImageClassification were initialized from the model checkpoint at /home/orelit/Projects -Sathsara/Planigo/Models/wine_low_variance_augmented_data_logs/checkpoint-2835.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ViTForImageClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "vit_model = ViTForImageClassification.from_pretrained(\n",
    "        trained_checkpoint,\n",
    "        num_labels=labels.num_classes,\n",
    "        id2label={index: label for index, label in enumerate(labels.names)},\n",
    "        label2id={label: index for index, label in enumerate(labels.names)}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "933c7b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label={index: label for index, label in enumerate(labels.names)}\n",
    "label2id={label: index for index, label in enumerate(labels.names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb660c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = Path(\"/home/orelit/Projects -Sathsara/Planigo/data/VIT_train_wine_low_variance_test\")\n",
    "\n",
    "# ds=ImageFolder(data_dir)\n",
    "# indices = torch.randperm(len(ds)).tolist()\n",
    "# n_val = math.floor(len(indices) * .15)\n",
    "# train_ds = torch.utils.data.Subset(ds, indices[:-n_val])\n",
    "# val_ds = torch.utils.data.Subset(ds, indices[-n_val:])\n",
    "\n",
    "\n",
    "# label2id = {}\n",
    "# id2label = {}\n",
    "# for i, class_name in enumerate(ds.classes):\n",
    "#   label2id[class_name] = str(i)\n",
    "#   id2label[str(i)] = class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6efba01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "test_data_path = '/home/orelit/Projects -Sathsara/Planigo/data/VIT_test_wine_low_variance_test/All_barcodes'\n",
    "\n",
    "image_paths = []\n",
    "for image in os.listdir(test_data_path):\n",
    "    img = test_data_path +'/'+image\n",
    "    image_paths.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "da86f4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(img_path):\n",
    "   im=Image.open(img_path)\n",
    "   encoding = feature_extractor(images=im, return_tensors=\"pt\")\n",
    "   encoding.keys()\n",
    "   pixel_values = encoding['pixel_values']\n",
    "   outputs = vit_model(pixel_values)\n",
    "   result = outputs.logits.softmax(1).argmax(1)\n",
    "   tensor_result = outputs.logits.softmax(1)\n",
    "   prob = torch.max(tensor_result)\n",
    "   new_result = result.tolist() \n",
    "   for i in new_result:\n",
    "     return(id2label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cd7e38b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction :  7290012576607\n",
      "real label :  7290008670142\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290000024264\n",
      "real label :  7290008801843\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290000024264\n",
      "real label :  7290000024264\n",
      "Correctly Classified\n",
      "......................................................\n",
      "prediction :  7290015781008\n",
      "real label :  7290015350150\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290015781008\n",
      "real label :  7290015350150\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290000023847\n",
      "real label :  7290000023847\n",
      "Correctly Classified\n",
      "......................................................\n",
      "prediction :  7290012576607\n",
      "real label :  7290012576607\n",
      "Correctly Classified\n",
      "......................................................\n",
      "prediction :  7290000024264\n",
      "real label :  7290000024264\n",
      "Correctly Classified\n",
      "......................................................\n",
      "prediction :  7290015781008\n",
      "real label :  7290015350150\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290000024264\n",
      "real label :  7290000024264\n",
      "Correctly Classified\n",
      "......................................................\n",
      "prediction :  7290000024264\n",
      "real label :  7290000023809\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290006256089\n",
      "real label :  7290006256089\n",
      "Correctly Classified\n",
      "......................................................\n",
      "prediction :  7290015781008\n",
      "real label :  7290015951227\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290015781008\n",
      "real label :  7290015781008\n",
      "Correctly Classified\n",
      "......................................................\n",
      "prediction :  7290006256089\n",
      "real label :  7290006256089\n",
      "Correctly Classified\n",
      "......................................................\n",
      "prediction :  7290000024264\n",
      "real label :  7290008801843\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290015781114\n",
      "real label :  7290015781114\n",
      "Correctly Classified\n",
      "......................................................\n",
      "prediction :  7290000024264\n",
      "real label :  7290008801843\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290012576607\n",
      "real label :  7290000023809\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290015781114\n",
      "real label :  7290015781114\n",
      "Correctly Classified\n",
      "......................................................\n",
      "prediction :  7290008670159\n",
      "real label :  7290008670159\n",
      "Correctly Classified\n",
      "......................................................\n",
      "prediction :  7290008804189\n",
      "real label :  7290008804189\n",
      "Correctly Classified\n",
      "......................................................\n",
      "prediction :  7290006256089\n",
      "real label :  7290008802512\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290006256089\n",
      "real label :  7290006256089\n",
      "Correctly Classified\n",
      "......................................................\n",
      "prediction :  7290000024264\n",
      "real label :  7290000024264\n",
      "Correctly Classified\n",
      "......................................................\n",
      "prediction :  7290015781008\n",
      "real label :  7290015781015\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290000024264\n",
      "real label :  7290014466609\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290012576607\n",
      "real label :  7290012576607\n",
      "Correctly Classified\n",
      "......................................................\n",
      "prediction :  7290008670159\n",
      "real label :  7290008670159\n",
      "Correctly Classified\n",
      "......................................................\n",
      "prediction :  7290015781008\n",
      "real label :  7290015350150\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290006256089\n",
      "real label :  7290008802512\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290015781008\n",
      "real label :  7290015781015\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290000024264\n",
      "real label :  7290000023809\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290000024264\n",
      "real label :  7290008801843\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290012576607\n",
      "real label :  7290008804189\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290012576607\n",
      "real label :  7290012576607\n",
      "Correctly Classified\n",
      "......................................................\n",
      "prediction :  7290006256089\n",
      "real label :  7290006256089\n",
      "Correctly Classified\n",
      "......................................................\n",
      "prediction :  7290015781008\n",
      "real label :  7290015350150\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290015781008\n",
      "real label :  7290015350150\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290015781008\n",
      "real label :  7290015951227\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290015781114\n",
      "real label :  7290015781114\n",
      "Correctly Classified\n",
      "......................................................\n",
      "prediction :  7290006256089\n",
      "real label :  7290008670159\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290015781008\n",
      "real label :  7290015951227\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290012576607\n",
      "real label :  7290012576607\n",
      "Correctly Classified\n",
      "......................................................\n",
      "prediction :  7290015781008\n",
      "real label :  7290015350150\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290015781008\n",
      "real label :  7290015350150\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290012576607\n",
      "real label :  7290008670142\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290006256089\n",
      "real label :  7290008802512\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290000023847\n",
      "real label :  7290000023847\n",
      "Correctly Classified\n",
      "......................................................\n",
      "prediction :  7290015781008\n",
      "real label :  7290015781008\n",
      "Correctly Classified\n",
      "......................................................\n",
      "prediction :  7290015781008\n",
      "real label :  7290015781015\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290000024264\n",
      "real label :  7290000023809\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290008670159\n",
      "real label :  7290008670159\n",
      "Correctly Classified\n",
      "......................................................\n",
      "prediction :  7290006256089\n",
      "real label :  7290008802512\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290000023847\n",
      "real label :  7290000023847\n",
      "Correctly Classified\n",
      "......................................................\n",
      "prediction :  7290000024264\n",
      "real label :  7290008801843\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290015781008\n",
      "real label :  7290015951227\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290015781008\n",
      "real label :  7290015781008\n",
      "Correctly Classified\n",
      "......................................................\n",
      "prediction :  7290015781114\n",
      "real label :  7290015781114\n",
      "Correctly Classified\n",
      "......................................................\n",
      "prediction :  7290000024264\n",
      "real label :  7290008801843\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290006256089\n",
      "real label :  7290006256089\n",
      "Correctly Classified\n",
      "......................................................\n",
      "prediction :  7290000024264\n",
      "real label :  7290008801843\n",
      "Not Classified\n",
      "......................................................\n",
      "prediction :  7290000024264\n",
      "real label :  7290000024264\n",
      "Correctly Classified\n",
      "......................................................\n",
      "prediction :  7290000024264\n",
      "real label :  7290000024264\n",
      "Correctly Classified\n",
      "......................................................\n",
      "prediction :  7290008670159\n",
      "real label :  7290008670159\n",
      "Correctly Classified\n",
      "......................................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction :  7290015781008\n",
      "real label :  7290015350150\n",
      "Not Classified\n",
      "......................................................\n",
      "Number of images :  66\n",
      "Number of correctly classified images :  30\n",
      "Accuray :  0.45454545454545453\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "count = 0\n",
    "correct = 0\n",
    "for image in os.listdir(test_data_path):\n",
    "    img = test_data_path +'/'+image\n",
    "    pred= prediction(img)\n",
    "    print(\"prediction : \",pred)\n",
    "    test_label = image[image.rfind('/')+1:]\n",
    "    real_class = test_label[0:13]\n",
    "    print(\"real label : \",real_class)\n",
    "    if real_class == pred:\n",
    "        correct = correct +1\n",
    "        print('Correctly Classified')\n",
    "    else:\n",
    "        print('Not Classified')\n",
    "    count = count + 1\n",
    "    print('......................................................')\n",
    "    \n",
    "acc = correct/count\n",
    "print(\"Number of images : \",count)\n",
    "print(\"Number of correctly classified images : \",correct)\n",
    "print(\"Accuray : \",acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
